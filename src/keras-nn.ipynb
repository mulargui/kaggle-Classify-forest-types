{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is my first experiment in this competition. Whereas XGBoost is highly recommended I rather tried to see how far I can go with an NN (using Keras).\n",
    "\n",
    "This is the basic model and with 250 epochs has an accuracy of 80% (really poor).\n",
    "\n",
    "I'll continue for a few days researching how much I can optimize this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['learn-together']\n",
      "['__notebook__.ipynb', '__output__.json']\n",
      "/kaggle/input/learn-together/test.csv\n",
      "/kaggle/input/learn-together/train.csv\n",
      "/kaggle/input/learn-together/sample_submission.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input/\"))\n",
    "print(os.listdir(\"../working/\"))\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "#load data, I had an issue with the data and hacked the data into the kernel\n",
    "#dftrain=pd.read_csv('/kaggle/input/train.csv')\n",
    "#dftest=pd.read_csv('/kaggle/input/test.csv')\n",
    "dftrain=pd.read_csv('/kaggle/input/learn-together/train.csv')\n",
    "dftest=pd.read_csv('/kaggle/input/learn-together/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
      "0   1       2596      51      3                               258   \n",
      "1   2       2590      56      2                               212   \n",
      "2   3       2804     139      9                               268   \n",
      "3   4       2785     155     18                               242   \n",
      "4   5       2595      45      2                               153   \n",
      "\n",
      "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
      "0                               0                              510   \n",
      "1                              -6                              390   \n",
      "2                              65                             3180   \n",
      "3                             118                             3090   \n",
      "4                              -1                              391   \n",
      "\n",
      "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  ...  Soil_Type32  \\\n",
      "0            221             232            148  ...            0   \n",
      "1            220             235            151  ...            0   \n",
      "2            234             238            135  ...            0   \n",
      "3            238             238            122  ...            0   \n",
      "4            220             234            150  ...            0   \n",
      "\n",
      "   Soil_Type33  Soil_Type34  Soil_Type35  Soil_Type36  Soil_Type37  \\\n",
      "0            0            0            0            0            0   \n",
      "1            0            0            0            0            0   \n",
      "2            0            0            0            0            0   \n",
      "3            0            0            0            0            0   \n",
      "4            0            0            0            0            0   \n",
      "\n",
      "   Soil_Type38  Soil_Type39  Soil_Type40  Cover_Type  \n",
      "0            0            0            0           5  \n",
      "1            0            0            0           5  \n",
      "2            0            0            0           2  \n",
      "3            0            0            0           2  \n",
      "4            0            0            0           5  \n",
      "\n",
      "[5 rows x 56 columns]\n",
      "15120\n",
      "      Id  Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
      "0  15121       2680     354     14                                 0   \n",
      "1  15122       2683       0     13                                 0   \n",
      "2  15123       2713      16     15                                 0   \n",
      "3  15124       2709      24     17                                 0   \n",
      "4  15125       2706      29     19                                 0   \n",
      "\n",
      "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
      "0                               0                             2684   \n",
      "1                               0                             2654   \n",
      "2                               0                             2980   \n",
      "3                               0                             2950   \n",
      "4                               0                             2920   \n",
      "\n",
      "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  ...  Soil_Type31  \\\n",
      "0            196             214            156  ...            0   \n",
      "1            201             216            152  ...            0   \n",
      "2            206             208            137  ...            0   \n",
      "3            208             201            125  ...            0   \n",
      "4            210             195            115  ...            0   \n",
      "\n",
      "   Soil_Type32  Soil_Type33  Soil_Type34  Soil_Type35  Soil_Type36  \\\n",
      "0            0            0            0            0            0   \n",
      "1            0            0            0            0            0   \n",
      "2            0            0            0            0            0   \n",
      "3            0            0            0            0            0   \n",
      "4            0            0            0            0            0   \n",
      "\n",
      "   Soil_Type37  Soil_Type38  Soil_Type39  Soil_Type40  \n",
      "0            0            0            0            0  \n",
      "1            0            0            0            0  \n",
      "2            0            0            0            0  \n",
      "3            0            0            0            0  \n",
      "4            0            0            0            0  \n",
      "\n",
      "[5 rows x 55 columns]\n",
      "565892\n"
     ]
    }
   ],
   "source": [
    "#file shape\n",
    "print(dftrain.head())\n",
    "print(dftrain.shape[0])\n",
    "print(dftest.head())\n",
    "print(dftest.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id                                    int64\n",
      "Elevation                             int64\n",
      "Aspect                                int64\n",
      "Slope                                 int64\n",
      "Horizontal_Distance_To_Hydrology      int64\n",
      "Vertical_Distance_To_Hydrology        int64\n",
      "Horizontal_Distance_To_Roadways       int64\n",
      "Hillshade_9am                         int64\n",
      "Hillshade_Noon                        int64\n",
      "Hillshade_3pm                         int64\n",
      "Horizontal_Distance_To_Fire_Points    int64\n",
      "Wilderness_Area1                      int64\n",
      "Wilderness_Area2                      int64\n",
      "Wilderness_Area3                      int64\n",
      "Wilderness_Area4                      int64\n",
      "Soil_Type1                            int64\n",
      "Soil_Type2                            int64\n",
      "Soil_Type3                            int64\n",
      "Soil_Type4                            int64\n",
      "Soil_Type5                            int64\n",
      "Soil_Type6                            int64\n",
      "Soil_Type7                            int64\n",
      "Soil_Type8                            int64\n",
      "Soil_Type9                            int64\n",
      "Soil_Type10                           int64\n",
      "Soil_Type11                           int64\n",
      "Soil_Type12                           int64\n",
      "Soil_Type13                           int64\n",
      "Soil_Type14                           int64\n",
      "Soil_Type15                           int64\n",
      "Soil_Type16                           int64\n",
      "Soil_Type17                           int64\n",
      "Soil_Type18                           int64\n",
      "Soil_Type19                           int64\n",
      "Soil_Type20                           int64\n",
      "Soil_Type21                           int64\n",
      "Soil_Type22                           int64\n",
      "Soil_Type23                           int64\n",
      "Soil_Type24                           int64\n",
      "Soil_Type25                           int64\n",
      "Soil_Type26                           int64\n",
      "Soil_Type27                           int64\n",
      "Soil_Type28                           int64\n",
      "Soil_Type29                           int64\n",
      "Soil_Type30                           int64\n",
      "Soil_Type31                           int64\n",
      "Soil_Type32                           int64\n",
      "Soil_Type33                           int64\n",
      "Soil_Type34                           int64\n",
      "Soil_Type35                           int64\n",
      "Soil_Type36                           int64\n",
      "Soil_Type37                           int64\n",
      "Soil_Type38                           int64\n",
      "Soil_Type39                           int64\n",
      "Soil_Type40                           int64\n",
      "Cover_Type                            int64\n",
      "dtype: object\n",
      "Id                                    int64\n",
      "Elevation                             int64\n",
      "Aspect                                int64\n",
      "Slope                                 int64\n",
      "Horizontal_Distance_To_Hydrology      int64\n",
      "Vertical_Distance_To_Hydrology        int64\n",
      "Horizontal_Distance_To_Roadways       int64\n",
      "Hillshade_9am                         int64\n",
      "Hillshade_Noon                        int64\n",
      "Hillshade_3pm                         int64\n",
      "Horizontal_Distance_To_Fire_Points    int64\n",
      "Wilderness_Area1                      int64\n",
      "Wilderness_Area2                      int64\n",
      "Wilderness_Area3                      int64\n",
      "Wilderness_Area4                      int64\n",
      "Soil_Type1                            int64\n",
      "Soil_Type2                            int64\n",
      "Soil_Type3                            int64\n",
      "Soil_Type4                            int64\n",
      "Soil_Type5                            int64\n",
      "Soil_Type6                            int64\n",
      "Soil_Type7                            int64\n",
      "Soil_Type8                            int64\n",
      "Soil_Type9                            int64\n",
      "Soil_Type10                           int64\n",
      "Soil_Type11                           int64\n",
      "Soil_Type12                           int64\n",
      "Soil_Type13                           int64\n",
      "Soil_Type14                           int64\n",
      "Soil_Type15                           int64\n",
      "Soil_Type16                           int64\n",
      "Soil_Type17                           int64\n",
      "Soil_Type18                           int64\n",
      "Soil_Type19                           int64\n",
      "Soil_Type20                           int64\n",
      "Soil_Type21                           int64\n",
      "Soil_Type22                           int64\n",
      "Soil_Type23                           int64\n",
      "Soil_Type24                           int64\n",
      "Soil_Type25                           int64\n",
      "Soil_Type26                           int64\n",
      "Soil_Type27                           int64\n",
      "Soil_Type28                           int64\n",
      "Soil_Type29                           int64\n",
      "Soil_Type30                           int64\n",
      "Soil_Type31                           int64\n",
      "Soil_Type32                           int64\n",
      "Soil_Type33                           int64\n",
      "Soil_Type34                           int64\n",
      "Soil_Type35                           int64\n",
      "Soil_Type36                           int64\n",
      "Soil_Type37                           int64\n",
      "Soil_Type38                           int64\n",
      "Soil_Type39                           int64\n",
      "Soil_Type40                           int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#features types\n",
    "print(dftrain.dtypes)\n",
    "print(dftest.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id                                    0\n",
      "Elevation                             0\n",
      "Aspect                                0\n",
      "Slope                                 0\n",
      "Horizontal_Distance_To_Hydrology      0\n",
      "Vertical_Distance_To_Hydrology        0\n",
      "Horizontal_Distance_To_Roadways       0\n",
      "Hillshade_9am                         0\n",
      "Hillshade_Noon                        0\n",
      "Hillshade_3pm                         0\n",
      "Horizontal_Distance_To_Fire_Points    0\n",
      "Wilderness_Area1                      0\n",
      "Wilderness_Area2                      0\n",
      "Wilderness_Area3                      0\n",
      "Wilderness_Area4                      0\n",
      "Soil_Type1                            0\n",
      "Soil_Type2                            0\n",
      "Soil_Type3                            0\n",
      "Soil_Type4                            0\n",
      "Soil_Type5                            0\n",
      "Soil_Type6                            0\n",
      "Soil_Type7                            0\n",
      "Soil_Type8                            0\n",
      "Soil_Type9                            0\n",
      "Soil_Type10                           0\n",
      "Soil_Type11                           0\n",
      "Soil_Type12                           0\n",
      "Soil_Type13                           0\n",
      "Soil_Type14                           0\n",
      "Soil_Type15                           0\n",
      "Soil_Type16                           0\n",
      "Soil_Type17                           0\n",
      "Soil_Type18                           0\n",
      "Soil_Type19                           0\n",
      "Soil_Type20                           0\n",
      "Soil_Type21                           0\n",
      "Soil_Type22                           0\n",
      "Soil_Type23                           0\n",
      "Soil_Type24                           0\n",
      "Soil_Type25                           0\n",
      "Soil_Type26                           0\n",
      "Soil_Type27                           0\n",
      "Soil_Type28                           0\n",
      "Soil_Type29                           0\n",
      "Soil_Type30                           0\n",
      "Soil_Type31                           0\n",
      "Soil_Type32                           0\n",
      "Soil_Type33                           0\n",
      "Soil_Type34                           0\n",
      "Soil_Type35                           0\n",
      "Soil_Type36                           0\n",
      "Soil_Type37                           0\n",
      "Soil_Type38                           0\n",
      "Soil_Type39                           0\n",
      "Soil_Type40                           0\n",
      "Cover_Type                            0\n",
      "dtype: int64\n",
      "Id                                    0\n",
      "Elevation                             0\n",
      "Aspect                                0\n",
      "Slope                                 0\n",
      "Horizontal_Distance_To_Hydrology      0\n",
      "Vertical_Distance_To_Hydrology        0\n",
      "Horizontal_Distance_To_Roadways       0\n",
      "Hillshade_9am                         0\n",
      "Hillshade_Noon                        0\n",
      "Hillshade_3pm                         0\n",
      "Horizontal_Distance_To_Fire_Points    0\n",
      "Wilderness_Area1                      0\n",
      "Wilderness_Area2                      0\n",
      "Wilderness_Area3                      0\n",
      "Wilderness_Area4                      0\n",
      "Soil_Type1                            0\n",
      "Soil_Type2                            0\n",
      "Soil_Type3                            0\n",
      "Soil_Type4                            0\n",
      "Soil_Type5                            0\n",
      "Soil_Type6                            0\n",
      "Soil_Type7                            0\n",
      "Soil_Type8                            0\n",
      "Soil_Type9                            0\n",
      "Soil_Type10                           0\n",
      "Soil_Type11                           0\n",
      "Soil_Type12                           0\n",
      "Soil_Type13                           0\n",
      "Soil_Type14                           0\n",
      "Soil_Type15                           0\n",
      "Soil_Type16                           0\n",
      "Soil_Type17                           0\n",
      "Soil_Type18                           0\n",
      "Soil_Type19                           0\n",
      "Soil_Type20                           0\n",
      "Soil_Type21                           0\n",
      "Soil_Type22                           0\n",
      "Soil_Type23                           0\n",
      "Soil_Type24                           0\n",
      "Soil_Type25                           0\n",
      "Soil_Type26                           0\n",
      "Soil_Type27                           0\n",
      "Soil_Type28                           0\n",
      "Soil_Type29                           0\n",
      "Soil_Type30                           0\n",
      "Soil_Type31                           0\n",
      "Soil_Type32                           0\n",
      "Soil_Type33                           0\n",
      "Soil_Type34                           0\n",
      "Soil_Type35                           0\n",
      "Soil_Type36                           0\n",
      "Soil_Type37                           0\n",
      "Soil_Type38                           0\n",
      "Soil_Type39                           0\n",
      "Soil_Type40                           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#validate files - nans per feature\n",
    "print(dftrain.isnull().sum(axis = 0))\n",
    "print(dftest.isnull().sum(axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#validate files - no rows with all zeros\n",
    "print(dftrain[dftrain.drop(['Id','Cover_Type'], axis=1).eq(0).all(1)].empty)\n",
    "print(dftest[dftest.drop('Id', axis=1).eq(0).all(1)].empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split train data in features and labels\n",
    "y = dftrain.Cover_Type\n",
    "x = dftrain.drop(['Id','Cover_Type'], axis=1)\n",
    "\n",
    "# split test data in features and Ids\n",
    "Ids = dftest.Id\n",
    "x_predict = dftest.drop('Id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#force all types to float\n",
    "x = x.astype(float)\n",
    "x_predict = x_predict.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize features\n",
    "#in the future it can be done more elegantly, for now just using the max min values of the data that we know\n",
    "#x['Elevation']=(x['Elevation']-x['Elevation'].min())/(x['Elevation'].max()-x['Elevation'].min())                             \n",
    "x['Elevation']=(x['Elevation']-1859)/(3858-1859)                             \n",
    "x['Aspect']=x['Aspect']/360                      \n",
    "x['Slope']=x['Slope']/66                      \n",
    "x['Horizontal_Distance_To_Hydrology']=x['Horizontal_Distance_To_Hydrology']/1397                      \n",
    "x['Vertical_Distance_To_Hydrology']=(x['Vertical_Distance_To_Hydrology']+173)/(601+173)                             \n",
    "x['Horizontal_Distance_To_Roadways']=x['Horizontal_Distance_To_Roadways']/7117                      \n",
    "x['Hillshade_9am']=x['Hillshade_9am']/254                      \n",
    "x['Hillshade_Noon']=x['Hillshade_Noon']/254                      \n",
    "x['Hillshade_3pm']=x['Hillshade_3pm']/254                      \n",
    "x['Horizontal_Distance_To_Fire_Points']=x['Horizontal_Distance_To_Fire_Points']/67173                      \n",
    "                                \n",
    "x_predict['Elevation']=(x_predict['Elevation']-1859)/(3858-1859)                             \n",
    "x_predict['Aspect']=x_predict['Aspect']/360                      \n",
    "x_predict['Slope']=x_predict['Slope']/66                      \n",
    "x_predict['Horizontal_Distance_To_Hydrology']=x_predict['Horizontal_Distance_To_Hydrology']/1397                      \n",
    "x_predict['Vertical_Distance_To_Hydrology']=(x_predict['Vertical_Distance_To_Hydrology']+173)/(601+173)                             \n",
    "x_predict['Horizontal_Distance_To_Roadways']=x_predict['Horizontal_Distance_To_Roadways']/7117                      \n",
    "x_predict['Hillshade_9am']=x_predict['Hillshade_9am']/254                      \n",
    "x_predict['Hillshade_Noon']=x_predict['Hillshade_Noon']/254                      \n",
    "x_predict['Hillshade_3pm']=x_predict['Hillshade_3pm']/254                      \n",
    "x_predict['Horizontal_Distance_To_Fire_Points']=x_predict['Horizontal_Distance_To_Fire_Points']/67173                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#validate data - no rows with all zeros\n",
    "#x.index[x.eq(0).all(1)]\n",
    "print(x[x.eq(0).all(1)].empty)\n",
    "print(x_predict[x_predict.eq(0).all(1)].empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# convert the label to One Hot Encoding\n",
    "#to_categorical requires 0..6 instead of 1..7\n",
    "y -=1\n",
    "y = y.to_numpy()\n",
    "\n",
    "num_classes = 7\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y = to_categorical(y, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the features dataframes to numpy arrays\n",
    "x = x.to_numpy()\n",
    "x_predict = x_predict.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split in train (80%) and test (20%) sets \n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#here is the NN model\n",
    "import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "num_features = 54\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=num_features, activation='relu', kernel_initializer='normal', input_dim=num_features))\n",
    "model.add(Dense(units=num_features*2, activation='relu', kernel_initializer='normal'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "#              optimizer='Adadelta',\n",
    "              optimizer='Adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12096 samples, validate on 3024 samples\n",
      "Epoch 1/250\n",
      "12096/12096 [==============================] - 1s 80us/sample - loss: 1.1389 - acc: 0.5398 - val_loss: 0.8916 - val_acc: 0.6002\n",
      "Epoch 2/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.8597 - acc: 0.6290 - val_loss: 0.8233 - val_acc: 0.6495\n",
      "Epoch 3/250\n",
      "12096/12096 [==============================] - 1s 58us/sample - loss: 0.8043 - acc: 0.6565 - val_loss: 0.7869 - val_acc: 0.6551\n",
      "Epoch 4/250\n",
      "12096/12096 [==============================] - 1s 56us/sample - loss: 0.7688 - acc: 0.6711 - val_loss: 0.7429 - val_acc: 0.6852\n",
      "Epoch 5/250\n",
      "12096/12096 [==============================] - 1s 58us/sample - loss: 0.7372 - acc: 0.6835 - val_loss: 0.7162 - val_acc: 0.6994\n",
      "Epoch 6/250\n",
      "12096/12096 [==============================] - 1s 58us/sample - loss: 0.7134 - acc: 0.6939 - val_loss: 0.7009 - val_acc: 0.7017\n",
      "Epoch 7/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.6960 - acc: 0.7039 - val_loss: 0.6849 - val_acc: 0.6964\n",
      "Epoch 8/250\n",
      "12096/12096 [==============================] - 1s 58us/sample - loss: 0.6820 - acc: 0.7042 - val_loss: 0.6845 - val_acc: 0.6997\n",
      "Epoch 9/250\n",
      "12096/12096 [==============================] - 1s 58us/sample - loss: 0.6689 - acc: 0.7162 - val_loss: 0.6933 - val_acc: 0.6974\n",
      "Epoch 10/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.6587 - acc: 0.7157 - val_loss: 0.6552 - val_acc: 0.7143\n",
      "Epoch 11/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.6531 - acc: 0.7202 - val_loss: 0.6463 - val_acc: 0.7192\n",
      "Epoch 12/250\n",
      "12096/12096 [==============================] - 1s 58us/sample - loss: 0.6414 - acc: 0.7228 - val_loss: 0.6370 - val_acc: 0.7235\n",
      "Epoch 13/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.6380 - acc: 0.7290 - val_loss: 0.6352 - val_acc: 0.7226\n",
      "Epoch 14/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.6323 - acc: 0.7279 - val_loss: 0.6564 - val_acc: 0.7153\n",
      "Epoch 15/250\n",
      "12096/12096 [==============================] - 1s 58us/sample - loss: 0.6279 - acc: 0.7295 - val_loss: 0.6264 - val_acc: 0.7269\n",
      "Epoch 16/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.6209 - acc: 0.7315 - val_loss: 0.6231 - val_acc: 0.7275\n",
      "Epoch 17/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.6167 - acc: 0.7347 - val_loss: 0.6281 - val_acc: 0.7249\n",
      "Epoch 18/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.6070 - acc: 0.7393 - val_loss: 0.6238 - val_acc: 0.7272\n",
      "Epoch 19/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.6058 - acc: 0.7385 - val_loss: 0.6118 - val_acc: 0.7354\n",
      "Epoch 20/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.6039 - acc: 0.7436 - val_loss: 0.6299 - val_acc: 0.7235\n",
      "Epoch 21/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.5957 - acc: 0.7440 - val_loss: 0.5972 - val_acc: 0.7474\n",
      "Epoch 22/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.5931 - acc: 0.7469 - val_loss: 0.5960 - val_acc: 0.7394\n",
      "Epoch 23/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.5888 - acc: 0.7488 - val_loss: 0.6076 - val_acc: 0.7348\n",
      "Epoch 24/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.5883 - acc: 0.7493 - val_loss: 0.6019 - val_acc: 0.7411\n",
      "Epoch 25/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.5800 - acc: 0.7548 - val_loss: 0.5840 - val_acc: 0.7526\n",
      "Epoch 26/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.5800 - acc: 0.7524 - val_loss: 0.5936 - val_acc: 0.7427\n",
      "Epoch 27/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.5743 - acc: 0.7569 - val_loss: 0.5866 - val_acc: 0.7460\n",
      "Epoch 28/250\n",
      "12096/12096 [==============================] - 1s 58us/sample - loss: 0.5712 - acc: 0.7545 - val_loss: 0.5800 - val_acc: 0.7427\n",
      "Epoch 29/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.5672 - acc: 0.7612 - val_loss: 0.5701 - val_acc: 0.7477\n",
      "Epoch 30/250\n",
      "12096/12096 [==============================] - 1s 58us/sample - loss: 0.5650 - acc: 0.7571 - val_loss: 0.5718 - val_acc: 0.7593\n",
      "Epoch 31/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.5618 - acc: 0.7612 - val_loss: 0.5764 - val_acc: 0.7427\n",
      "Epoch 32/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.5549 - acc: 0.7655 - val_loss: 0.5754 - val_acc: 0.7480\n",
      "Epoch 33/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.5563 - acc: 0.7629 - val_loss: 0.5740 - val_acc: 0.7483\n",
      "Epoch 34/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.5537 - acc: 0.7654 - val_loss: 0.5565 - val_acc: 0.7599\n",
      "Epoch 35/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.5497 - acc: 0.7646 - val_loss: 0.5567 - val_acc: 0.7692\n",
      "Epoch 36/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.5478 - acc: 0.7712 - val_loss: 0.5525 - val_acc: 0.7655\n",
      "Epoch 37/250\n",
      "12096/12096 [==============================] - 1s 58us/sample - loss: 0.5429 - acc: 0.7720 - val_loss: 0.5481 - val_acc: 0.7665\n",
      "Epoch 38/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.5415 - acc: 0.7715 - val_loss: 0.5548 - val_acc: 0.7589\n",
      "Epoch 39/250\n",
      "12096/12096 [==============================] - 1s 58us/sample - loss: 0.5320 - acc: 0.7748 - val_loss: 0.5569 - val_acc: 0.7606\n",
      "Epoch 40/250\n",
      "12096/12096 [==============================] - 1s 58us/sample - loss: 0.5334 - acc: 0.7723 - val_loss: 0.5402 - val_acc: 0.7698\n",
      "Epoch 41/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.5304 - acc: 0.7767 - val_loss: 0.5416 - val_acc: 0.7612\n",
      "Epoch 42/250\n",
      "12096/12096 [==============================] - 1s 59us/sample - loss: 0.5301 - acc: 0.7741 - val_loss: 0.5494 - val_acc: 0.7642\n",
      "Epoch 43/250\n",
      "12096/12096 [==============================] - 1s 58us/sample - loss: 0.5253 - acc: 0.7800 - val_loss: 0.5417 - val_acc: 0.7669\n",
      "Epoch 44/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.5224 - acc: 0.7767 - val_loss: 0.5370 - val_acc: 0.7708\n",
      "Epoch 45/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.5211 - acc: 0.7780 - val_loss: 0.5288 - val_acc: 0.7718\n",
      "Epoch 46/250\n",
      "12096/12096 [==============================] - 1s 58us/sample - loss: 0.5162 - acc: 0.7829 - val_loss: 0.5382 - val_acc: 0.7642\n",
      "Epoch 47/250\n",
      "12096/12096 [==============================] - 1s 58us/sample - loss: 0.5114 - acc: 0.7854 - val_loss: 0.5393 - val_acc: 0.7708\n",
      "Epoch 48/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.5109 - acc: 0.7851 - val_loss: 0.5463 - val_acc: 0.7695\n",
      "Epoch 49/250\n",
      "12096/12096 [==============================] - 1s 58us/sample - loss: 0.5082 - acc: 0.7837 - val_loss: 0.5265 - val_acc: 0.7738\n",
      "Epoch 50/250\n",
      "12096/12096 [==============================] - 1s 58us/sample - loss: 0.5075 - acc: 0.7879 - val_loss: 0.5403 - val_acc: 0.7738\n",
      "Epoch 51/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.5038 - acc: 0.7874 - val_loss: 0.5357 - val_acc: 0.7698\n",
      "Epoch 52/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.5002 - acc: 0.7909 - val_loss: 0.5154 - val_acc: 0.7765\n",
      "Epoch 53/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.4979 - acc: 0.7917 - val_loss: 0.5323 - val_acc: 0.7755\n",
      "Epoch 54/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.4979 - acc: 0.7906 - val_loss: 0.5270 - val_acc: 0.7688\n",
      "Epoch 55/250\n",
      "12096/12096 [==============================] - 1s 59us/sample - loss: 0.4930 - acc: 0.7918 - val_loss: 0.5196 - val_acc: 0.7851\n",
      "Epoch 56/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.4915 - acc: 0.7894 - val_loss: 0.5251 - val_acc: 0.7814\n",
      "Epoch 57/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.4894 - acc: 0.7958 - val_loss: 0.5183 - val_acc: 0.7837\n",
      "Epoch 58/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.4855 - acc: 0.7964 - val_loss: 0.5597 - val_acc: 0.7675\n",
      "Epoch 59/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.4878 - acc: 0.7946 - val_loss: 0.5177 - val_acc: 0.7817\n",
      "Epoch 60/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.4858 - acc: 0.7940 - val_loss: 0.5128 - val_acc: 0.7834\n",
      "Epoch 61/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.4801 - acc: 0.7956 - val_loss: 0.5118 - val_acc: 0.7831\n",
      "Epoch 62/250\n",
      "12096/12096 [==============================] - 1s 58us/sample - loss: 0.4786 - acc: 0.8007 - val_loss: 0.5292 - val_acc: 0.7765\n",
      "Epoch 63/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.4759 - acc: 0.8023 - val_loss: 0.5030 - val_acc: 0.7864\n",
      "Epoch 64/250\n",
      "12096/12096 [==============================] - 1s 58us/sample - loss: 0.4733 - acc: 0.7975 - val_loss: 0.4997 - val_acc: 0.7920\n",
      "Epoch 65/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.4707 - acc: 0.8034 - val_loss: 0.5061 - val_acc: 0.7864\n",
      "Epoch 66/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.4720 - acc: 0.8028 - val_loss: 0.5127 - val_acc: 0.7768\n",
      "Epoch 67/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.4711 - acc: 0.8022 - val_loss: 0.5055 - val_acc: 0.7857\n",
      "Epoch 68/250\n",
      "12096/12096 [==============================] - 1s 58us/sample - loss: 0.4670 - acc: 0.8042 - val_loss: 0.4973 - val_acc: 0.7880\n",
      "Epoch 69/250\n",
      "12096/12096 [==============================] - 1s 59us/sample - loss: 0.4645 - acc: 0.8029 - val_loss: 0.4967 - val_acc: 0.7930\n",
      "Epoch 70/250\n",
      "12096/12096 [==============================] - 1s 58us/sample - loss: 0.4619 - acc: 0.8065 - val_loss: 0.5083 - val_acc: 0.7804\n",
      "Epoch 71/250\n",
      "12096/12096 [==============================] - 1s 59us/sample - loss: 0.4612 - acc: 0.8062 - val_loss: 0.5004 - val_acc: 0.7860\n",
      "Epoch 72/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.4580 - acc: 0.8075 - val_loss: 0.4982 - val_acc: 0.7831\n",
      "Epoch 73/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.4554 - acc: 0.8113 - val_loss: 0.4929 - val_acc: 0.7986\n",
      "Epoch 74/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.4558 - acc: 0.8064 - val_loss: 0.5077 - val_acc: 0.7950\n",
      "Epoch 75/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.4544 - acc: 0.8113 - val_loss: 0.4958 - val_acc: 0.7890\n",
      "Epoch 76/250\n",
      "12096/12096 [==============================] - 1s 58us/sample - loss: 0.4497 - acc: 0.8137 - val_loss: 0.4912 - val_acc: 0.7920\n",
      "Epoch 77/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.4481 - acc: 0.8116 - val_loss: 0.4953 - val_acc: 0.7903\n",
      "Epoch 78/250\n",
      "12096/12096 [==============================] - 1s 58us/sample - loss: 0.4505 - acc: 0.8101 - val_loss: 0.4817 - val_acc: 0.7946\n",
      "Epoch 79/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.4486 - acc: 0.8109 - val_loss: 0.5032 - val_acc: 0.7887\n",
      "Epoch 80/250\n",
      "12096/12096 [==============================] - 1s 58us/sample - loss: 0.4458 - acc: 0.8132 - val_loss: 0.4950 - val_acc: 0.7923\n",
      "Epoch 81/250\n",
      "12096/12096 [==============================] - 1s 58us/sample - loss: 0.4458 - acc: 0.8147 - val_loss: 0.4924 - val_acc: 0.7900\n",
      "Epoch 82/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.4431 - acc: 0.8179 - val_loss: 0.4934 - val_acc: 0.7960\n",
      "Epoch 83/250\n",
      "12096/12096 [==============================] - 1s 58us/sample - loss: 0.4418 - acc: 0.8151 - val_loss: 0.4872 - val_acc: 0.7946\n",
      "Epoch 84/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.4404 - acc: 0.8148 - val_loss: 0.4775 - val_acc: 0.8029\n",
      "Epoch 85/250\n",
      "12096/12096 [==============================] - 1s 58us/sample - loss: 0.4380 - acc: 0.8167 - val_loss: 0.4856 - val_acc: 0.7979\n",
      "Epoch 86/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.4374 - acc: 0.8161 - val_loss: 0.4852 - val_acc: 0.8003\n",
      "Epoch 87/250\n",
      "12096/12096 [==============================] - 1s 61us/sample - loss: 0.4326 - acc: 0.8210 - val_loss: 0.4900 - val_acc: 0.7963\n",
      "Epoch 88/250\n",
      "12096/12096 [==============================] - 1s 61us/sample - loss: 0.4345 - acc: 0.8193 - val_loss: 0.4827 - val_acc: 0.8016\n",
      "Epoch 89/250\n",
      "12096/12096 [==============================] - 1s 58us/sample - loss: 0.4298 - acc: 0.8216 - val_loss: 0.4794 - val_acc: 0.8016\n",
      "Epoch 90/250\n",
      "12096/12096 [==============================] - 1s 58us/sample - loss: 0.4310 - acc: 0.8201 - val_loss: 0.4714 - val_acc: 0.8065\n",
      "Epoch 91/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.4304 - acc: 0.8202 - val_loss: 0.4767 - val_acc: 0.8065\n",
      "Epoch 92/250\n",
      "12096/12096 [==============================] - 1s 58us/sample - loss: 0.4280 - acc: 0.8221 - val_loss: 0.4858 - val_acc: 0.7996\n",
      "Epoch 93/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.4266 - acc: 0.8214 - val_loss: 0.4901 - val_acc: 0.7880\n",
      "Epoch 94/250\n",
      "12096/12096 [==============================] - 1s 56us/sample - loss: 0.4262 - acc: 0.8202 - val_loss: 0.4771 - val_acc: 0.7983\n",
      "Epoch 95/250\n",
      "12096/12096 [==============================] - 1s 58us/sample - loss: 0.4258 - acc: 0.8232 - val_loss: 0.4797 - val_acc: 0.8059\n",
      "Epoch 96/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.4214 - acc: 0.8257 - val_loss: 0.4879 - val_acc: 0.8003\n",
      "Epoch 97/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.4222 - acc: 0.8239 - val_loss: 0.4692 - val_acc: 0.8079\n",
      "Epoch 98/250\n",
      "12096/12096 [==============================] - 1s 58us/sample - loss: 0.4226 - acc: 0.8232 - val_loss: 0.4933 - val_acc: 0.8019\n",
      "Epoch 99/250\n",
      "12096/12096 [==============================] - 1s 59us/sample - loss: 0.4161 - acc: 0.8258 - val_loss: 0.4725 - val_acc: 0.8128\n",
      "Epoch 100/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.4153 - acc: 0.8281 - val_loss: 0.4735 - val_acc: 0.8065\n",
      "Epoch 101/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.4169 - acc: 0.8251 - val_loss: 0.4625 - val_acc: 0.8151\n",
      "Epoch 102/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.4180 - acc: 0.8248 - val_loss: 0.4648 - val_acc: 0.8155\n",
      "Epoch 103/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.4139 - acc: 0.8299 - val_loss: 0.4791 - val_acc: 0.8046\n",
      "Epoch 104/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.4101 - acc: 0.8289 - val_loss: 0.4721 - val_acc: 0.8049\n",
      "Epoch 105/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.4113 - acc: 0.8299 - val_loss: 0.4689 - val_acc: 0.8082\n",
      "Epoch 106/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.4065 - acc: 0.8308 - val_loss: 0.4702 - val_acc: 0.8059\n",
      "Epoch 107/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.4067 - acc: 0.8328 - val_loss: 0.4841 - val_acc: 0.8082\n",
      "Epoch 108/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.4042 - acc: 0.8328 - val_loss: 0.4639 - val_acc: 0.8092\n",
      "Epoch 109/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.4055 - acc: 0.8307 - val_loss: 0.4742 - val_acc: 0.8006\n",
      "Epoch 110/250\n",
      "12096/12096 [==============================] - 1s 56us/sample - loss: 0.4020 - acc: 0.8303 - val_loss: 0.4682 - val_acc: 0.8115\n",
      "Epoch 111/250\n",
      "12096/12096 [==============================] - 1s 58us/sample - loss: 0.4022 - acc: 0.8318 - val_loss: 0.4618 - val_acc: 0.8148\n",
      "Epoch 112/250\n",
      "12096/12096 [==============================] - 1s 58us/sample - loss: 0.4037 - acc: 0.8306 - val_loss: 0.4907 - val_acc: 0.8036\n",
      "Epoch 113/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.4012 - acc: 0.8344 - val_loss: 0.4672 - val_acc: 0.8099\n",
      "Epoch 114/250\n",
      "12096/12096 [==============================] - 1s 58us/sample - loss: 0.3976 - acc: 0.8371 - val_loss: 0.4841 - val_acc: 0.8032\n",
      "Epoch 115/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.4014 - acc: 0.8313 - val_loss: 0.4672 - val_acc: 0.8128\n",
      "Epoch 116/250\n",
      "12096/12096 [==============================] - 1s 56us/sample - loss: 0.3948 - acc: 0.8404 - val_loss: 0.4617 - val_acc: 0.8178\n",
      "Epoch 117/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.3930 - acc: 0.8380 - val_loss: 0.4698 - val_acc: 0.8089\n",
      "Epoch 118/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.3979 - acc: 0.8352 - val_loss: 0.4676 - val_acc: 0.8145\n",
      "Epoch 119/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.3883 - acc: 0.8391 - val_loss: 0.4720 - val_acc: 0.8049\n",
      "Epoch 120/250\n",
      "12096/12096 [==============================] - 1s 58us/sample - loss: 0.3890 - acc: 0.8391 - val_loss: 0.4704 - val_acc: 0.8029\n",
      "Epoch 121/250\n",
      "12096/12096 [==============================] - 1s 58us/sample - loss: 0.3916 - acc: 0.8369 - val_loss: 0.4736 - val_acc: 0.8079\n",
      "Epoch 122/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.3898 - acc: 0.8404 - val_loss: 0.4790 - val_acc: 0.8089\n",
      "Epoch 123/250\n",
      "12096/12096 [==============================] - 1s 58us/sample - loss: 0.3862 - acc: 0.8428 - val_loss: 0.4767 - val_acc: 0.8092\n",
      "Epoch 124/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.3858 - acc: 0.8418 - val_loss: 0.4702 - val_acc: 0.8069\n",
      "Epoch 125/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.3849 - acc: 0.8409 - val_loss: 0.4726 - val_acc: 0.8138\n",
      "Epoch 126/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.3838 - acc: 0.8413 - val_loss: 0.4601 - val_acc: 0.8201\n",
      "Epoch 127/250\n",
      "12096/12096 [==============================] - 1s 58us/sample - loss: 0.3814 - acc: 0.8418 - val_loss: 0.4602 - val_acc: 0.8151\n",
      "Epoch 128/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.3832 - acc: 0.8406 - val_loss: 0.4684 - val_acc: 0.8175\n",
      "Epoch 129/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.3825 - acc: 0.8412 - val_loss: 0.4571 - val_acc: 0.8214\n",
      "Epoch 130/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.3794 - acc: 0.8445 - val_loss: 0.4583 - val_acc: 0.8142\n",
      "Epoch 131/250\n",
      "12096/12096 [==============================] - 1s 58us/sample - loss: 0.3781 - acc: 0.8434 - val_loss: 0.4552 - val_acc: 0.8161\n",
      "Epoch 132/250\n",
      "12096/12096 [==============================] - 1s 58us/sample - loss: 0.3758 - acc: 0.8452 - val_loss: 0.4532 - val_acc: 0.8221\n",
      "Epoch 133/250\n",
      "12096/12096 [==============================] - 1s 58us/sample - loss: 0.3750 - acc: 0.8472 - val_loss: 0.4613 - val_acc: 0.8138\n",
      "Epoch 134/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.3723 - acc: 0.8461 - val_loss: 0.4612 - val_acc: 0.8191\n",
      "Epoch 135/250\n",
      "12096/12096 [==============================] - 1s 58us/sample - loss: 0.3744 - acc: 0.8452 - val_loss: 0.4518 - val_acc: 0.8241\n",
      "Epoch 136/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.3741 - acc: 0.8475 - val_loss: 0.4681 - val_acc: 0.8079\n",
      "Epoch 137/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.3733 - acc: 0.8465 - val_loss: 0.4635 - val_acc: 0.8062\n",
      "Epoch 138/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.3692 - acc: 0.8512 - val_loss: 0.4626 - val_acc: 0.8158\n",
      "Epoch 139/250\n",
      "12096/12096 [==============================] - 1s 58us/sample - loss: 0.3684 - acc: 0.8481 - val_loss: 0.4633 - val_acc: 0.8142\n",
      "Epoch 140/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.3701 - acc: 0.8489 - val_loss: 0.4635 - val_acc: 0.8122\n",
      "Epoch 141/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.3653 - acc: 0.8526 - val_loss: 0.4829 - val_acc: 0.8145\n",
      "Epoch 142/250\n",
      "12096/12096 [==============================] - 1s 58us/sample - loss: 0.3677 - acc: 0.8469 - val_loss: 0.4653 - val_acc: 0.8214\n",
      "Epoch 143/250\n",
      "12096/12096 [==============================] - 1s 58us/sample - loss: 0.3631 - acc: 0.8512 - val_loss: 0.4690 - val_acc: 0.8132\n",
      "Epoch 144/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.3670 - acc: 0.8487 - val_loss: 0.4692 - val_acc: 0.8105\n",
      "Epoch 145/250\n",
      "12096/12096 [==============================] - 1s 58us/sample - loss: 0.3611 - acc: 0.8509 - val_loss: 0.4511 - val_acc: 0.8218\n",
      "Epoch 146/250\n",
      "12096/12096 [==============================] - 1s 58us/sample - loss: 0.3625 - acc: 0.8515 - val_loss: 0.4612 - val_acc: 0.8142\n",
      "Epoch 147/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.3617 - acc: 0.8515 - val_loss: 0.4507 - val_acc: 0.8234\n",
      "Epoch 148/250\n",
      "12096/12096 [==============================] - 1s 59us/sample - loss: 0.3634 - acc: 0.8533 - val_loss: 0.4746 - val_acc: 0.8049\n",
      "Epoch 149/250\n",
      "12096/12096 [==============================] - 1s 59us/sample - loss: 0.3596 - acc: 0.8530 - val_loss: 0.4449 - val_acc: 0.8287\n",
      "Epoch 150/250\n",
      "12096/12096 [==============================] - 1s 76us/sample - loss: 0.3528 - acc: 0.8524 - val_loss: 0.4619 - val_acc: 0.8181\n",
      "Epoch 151/250\n",
      "12096/12096 [==============================] - 1s 60us/sample - loss: 0.3564 - acc: 0.8553 - val_loss: 0.4719 - val_acc: 0.8102\n",
      "Epoch 152/250\n",
      "12096/12096 [==============================] - 1s 60us/sample - loss: 0.3553 - acc: 0.8554 - val_loss: 0.4574 - val_acc: 0.8284\n",
      "Epoch 153/250\n",
      "12096/12096 [==============================] - 1s 58us/sample - loss: 0.3531 - acc: 0.8575 - val_loss: 0.4609 - val_acc: 0.8161\n",
      "Epoch 154/250\n",
      "12096/12096 [==============================] - 1s 60us/sample - loss: 0.3559 - acc: 0.8542 - val_loss: 0.4579 - val_acc: 0.8185\n",
      "Epoch 155/250\n",
      "12096/12096 [==============================] - 1s 59us/sample - loss: 0.3533 - acc: 0.8565 - val_loss: 0.4605 - val_acc: 0.8208\n",
      "Epoch 156/250\n",
      "12096/12096 [==============================] - 1s 59us/sample - loss: 0.3492 - acc: 0.8546 - val_loss: 0.4579 - val_acc: 0.8181\n",
      "Epoch 157/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.3511 - acc: 0.8585 - val_loss: 0.4748 - val_acc: 0.8105\n",
      "Epoch 158/250\n",
      "12096/12096 [==============================] - 1s 58us/sample - loss: 0.3544 - acc: 0.8548 - val_loss: 0.4637 - val_acc: 0.8181\n",
      "Epoch 159/250\n",
      "12096/12096 [==============================] - 1s 59us/sample - loss: 0.3464 - acc: 0.8604 - val_loss: 0.4711 - val_acc: 0.8165\n",
      "Epoch 160/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.3495 - acc: 0.8585 - val_loss: 0.4528 - val_acc: 0.8317\n",
      "Epoch 161/250\n",
      "12096/12096 [==============================] - 1s 58us/sample - loss: 0.3465 - acc: 0.8580 - val_loss: 0.4533 - val_acc: 0.8254\n",
      "Epoch 162/250\n",
      "12096/12096 [==============================] - 1s 58us/sample - loss: 0.3454 - acc: 0.8587 - val_loss: 0.4574 - val_acc: 0.8218\n",
      "Epoch 163/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.3463 - acc: 0.8590 - val_loss: 0.4782 - val_acc: 0.8108\n",
      "Epoch 164/250\n",
      "12096/12096 [==============================] - 1s 58us/sample - loss: 0.3463 - acc: 0.8564 - val_loss: 0.4611 - val_acc: 0.8204\n",
      "Epoch 165/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.3470 - acc: 0.8568 - val_loss: 0.4535 - val_acc: 0.8204\n",
      "Epoch 166/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.3387 - acc: 0.8628 - val_loss: 0.4649 - val_acc: 0.8201\n",
      "Epoch 167/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.3432 - acc: 0.8619 - val_loss: 0.4386 - val_acc: 0.8323\n",
      "Epoch 168/250\n",
      "12096/12096 [==============================] - 1s 58us/sample - loss: 0.3394 - acc: 0.8590 - val_loss: 0.5062 - val_acc: 0.8052\n",
      "Epoch 169/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.3433 - acc: 0.8604 - val_loss: 0.4639 - val_acc: 0.8191\n",
      "Epoch 170/250\n",
      "12096/12096 [==============================] - 1s 58us/sample - loss: 0.3400 - acc: 0.8622 - val_loss: 0.4783 - val_acc: 0.8168\n",
      "Epoch 171/250\n",
      "12096/12096 [==============================] - 1s 59us/sample - loss: 0.3416 - acc: 0.8600 - val_loss: 0.4715 - val_acc: 0.8122\n",
      "Epoch 172/250\n",
      "12096/12096 [==============================] - 1s 59us/sample - loss: 0.3389 - acc: 0.8614 - val_loss: 0.4578 - val_acc: 0.8254\n",
      "Epoch 173/250\n",
      "12096/12096 [==============================] - 1s 58us/sample - loss: 0.3374 - acc: 0.8614 - val_loss: 0.4870 - val_acc: 0.8089\n",
      "Epoch 174/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.3391 - acc: 0.8585 - val_loss: 0.4612 - val_acc: 0.8201\n",
      "Epoch 175/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.3379 - acc: 0.8622 - val_loss: 0.4558 - val_acc: 0.8244\n",
      "Epoch 176/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.3362 - acc: 0.8633 - val_loss: 0.4590 - val_acc: 0.8214\n",
      "Epoch 177/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.3354 - acc: 0.8628 - val_loss: 0.4491 - val_acc: 0.8297\n",
      "Epoch 178/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.3343 - acc: 0.8617 - val_loss: 0.4509 - val_acc: 0.8280\n",
      "Epoch 179/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.3317 - acc: 0.8658 - val_loss: 0.4582 - val_acc: 0.8264\n",
      "Epoch 180/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.3306 - acc: 0.8647 - val_loss: 0.4528 - val_acc: 0.8237\n",
      "Epoch 181/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.3296 - acc: 0.8665 - val_loss: 0.4809 - val_acc: 0.8138\n",
      "Epoch 182/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.3327 - acc: 0.8652 - val_loss: 0.4511 - val_acc: 0.8244\n",
      "Epoch 183/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.3323 - acc: 0.8636 - val_loss: 0.4573 - val_acc: 0.8304\n",
      "Epoch 184/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.3294 - acc: 0.8649 - val_loss: 0.4504 - val_acc: 0.8280\n",
      "Epoch 185/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.3241 - acc: 0.8667 - val_loss: 0.4560 - val_acc: 0.8221\n",
      "Epoch 186/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.3236 - acc: 0.8690 - val_loss: 0.4602 - val_acc: 0.8271\n",
      "Epoch 187/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.3275 - acc: 0.8684 - val_loss: 0.4601 - val_acc: 0.8277\n",
      "Epoch 188/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.3262 - acc: 0.8668 - val_loss: 0.4931 - val_acc: 0.8138\n",
      "Epoch 189/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.3264 - acc: 0.8681 - val_loss: 0.4503 - val_acc: 0.8280\n",
      "Epoch 190/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.3253 - acc: 0.8671 - val_loss: 0.4534 - val_acc: 0.8280\n",
      "Epoch 191/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.3236 - acc: 0.8688 - val_loss: 0.4612 - val_acc: 0.8264\n",
      "Epoch 192/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.3224 - acc: 0.8696 - val_loss: 0.4684 - val_acc: 0.8234\n",
      "Epoch 193/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.3226 - acc: 0.8690 - val_loss: 0.4620 - val_acc: 0.8221\n",
      "Epoch 194/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.3224 - acc: 0.8679 - val_loss: 0.4612 - val_acc: 0.8228\n",
      "Epoch 195/250\n",
      "12096/12096 [==============================] - 1s 58us/sample - loss: 0.3252 - acc: 0.8688 - val_loss: 0.4845 - val_acc: 0.8158\n",
      "Epoch 196/250\n",
      "12096/12096 [==============================] - 1s 58us/sample - loss: 0.3182 - acc: 0.8733 - val_loss: 0.4584 - val_acc: 0.8327\n",
      "Epoch 197/250\n",
      "12096/12096 [==============================] - 1s 56us/sample - loss: 0.3247 - acc: 0.8701 - val_loss: 0.4633 - val_acc: 0.8234\n",
      "Epoch 198/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.3164 - acc: 0.8729 - val_loss: 0.4608 - val_acc: 0.8277\n",
      "Epoch 199/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.3155 - acc: 0.8743 - val_loss: 0.4680 - val_acc: 0.8204\n",
      "Epoch 200/250\n",
      "12096/12096 [==============================] - 1s 56us/sample - loss: 0.3192 - acc: 0.8714 - val_loss: 0.4540 - val_acc: 0.8294\n",
      "Epoch 201/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.3135 - acc: 0.8759 - val_loss: 0.4546 - val_acc: 0.8307\n",
      "Epoch 202/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.3175 - acc: 0.8707 - val_loss: 0.4536 - val_acc: 0.8277\n",
      "Epoch 203/250\n",
      "12096/12096 [==============================] - 1s 58us/sample - loss: 0.3164 - acc: 0.8722 - val_loss: 0.4522 - val_acc: 0.8360\n",
      "Epoch 204/250\n",
      "12096/12096 [==============================] - 1s 58us/sample - loss: 0.3148 - acc: 0.8706 - val_loss: 0.4503 - val_acc: 0.8353\n",
      "Epoch 205/250\n",
      "12096/12096 [==============================] - 1s 58us/sample - loss: 0.3131 - acc: 0.8743 - val_loss: 0.4594 - val_acc: 0.8323\n",
      "Epoch 206/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.3112 - acc: 0.8750 - val_loss: 0.4592 - val_acc: 0.8267\n",
      "Epoch 207/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.3087 - acc: 0.8762 - val_loss: 0.4593 - val_acc: 0.8271\n",
      "Epoch 208/250\n",
      "12096/12096 [==============================] - 1s 58us/sample - loss: 0.3134 - acc: 0.8716 - val_loss: 0.4661 - val_acc: 0.8271\n",
      "Epoch 209/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.3133 - acc: 0.8719 - val_loss: 0.4745 - val_acc: 0.8257\n",
      "Epoch 210/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.3085 - acc: 0.8728 - val_loss: 0.4734 - val_acc: 0.8261\n",
      "Epoch 211/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.3087 - acc: 0.8770 - val_loss: 0.4510 - val_acc: 0.8284\n",
      "Epoch 212/250\n",
      "12096/12096 [==============================] - 1s 56us/sample - loss: 0.3065 - acc: 0.8764 - val_loss: 0.4656 - val_acc: 0.8310\n",
      "Epoch 213/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.3057 - acc: 0.8771 - val_loss: 0.4515 - val_acc: 0.8284\n",
      "Epoch 214/250\n",
      "12096/12096 [==============================] - 1s 56us/sample - loss: 0.3113 - acc: 0.8741 - val_loss: 0.4851 - val_acc: 0.8171\n",
      "Epoch 215/250\n",
      "12096/12096 [==============================] - 1s 56us/sample - loss: 0.3052 - acc: 0.8782 - val_loss: 0.4516 - val_acc: 0.8310\n",
      "Epoch 216/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.3079 - acc: 0.8777 - val_loss: 0.4534 - val_acc: 0.8337\n",
      "Epoch 217/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.3053 - acc: 0.8747 - val_loss: 0.4739 - val_acc: 0.8264\n",
      "Epoch 218/250\n",
      "12096/12096 [==============================] - 1s 56us/sample - loss: 0.3063 - acc: 0.8763 - val_loss: 0.4541 - val_acc: 0.8218\n",
      "Epoch 219/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.3061 - acc: 0.8724 - val_loss: 0.4616 - val_acc: 0.8307\n",
      "Epoch 220/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.3038 - acc: 0.8780 - val_loss: 0.4675 - val_acc: 0.8231\n",
      "Epoch 221/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.3036 - acc: 0.8785 - val_loss: 0.4654 - val_acc: 0.8310\n",
      "Epoch 222/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.2996 - acc: 0.8788 - val_loss: 0.4627 - val_acc: 0.8300\n",
      "Epoch 223/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.2997 - acc: 0.8798 - val_loss: 0.4626 - val_acc: 0.8353\n",
      "Epoch 224/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.3004 - acc: 0.8799 - val_loss: 0.4742 - val_acc: 0.8168\n",
      "Epoch 225/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.3005 - acc: 0.8784 - val_loss: 0.4651 - val_acc: 0.8287\n",
      "Epoch 226/250\n",
      "12096/12096 [==============================] - 1s 56us/sample - loss: 0.3021 - acc: 0.8786 - val_loss: 0.4642 - val_acc: 0.8330\n",
      "Epoch 227/250\n",
      "12096/12096 [==============================] - 1s 56us/sample - loss: 0.2994 - acc: 0.8794 - val_loss: 0.4750 - val_acc: 0.8231\n",
      "Epoch 228/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.3035 - acc: 0.8758 - val_loss: 0.4623 - val_acc: 0.8373\n",
      "Epoch 229/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.2987 - acc: 0.8827 - val_loss: 0.4771 - val_acc: 0.8241\n",
      "Epoch 230/250\n",
      "12096/12096 [==============================] - 1s 59us/sample - loss: 0.2962 - acc: 0.8814 - val_loss: 0.4529 - val_acc: 0.8370\n",
      "Epoch 231/250\n",
      "12096/12096 [==============================] - 1s 61us/sample - loss: 0.2947 - acc: 0.8817 - val_loss: 0.4802 - val_acc: 0.8254\n",
      "Epoch 232/250\n",
      "12096/12096 [==============================] - 1s 60us/sample - loss: 0.2962 - acc: 0.8817 - val_loss: 0.4632 - val_acc: 0.8320\n",
      "Epoch 233/250\n",
      "12096/12096 [==============================] - 1s 61us/sample - loss: 0.2964 - acc: 0.8830 - val_loss: 0.4796 - val_acc: 0.8231\n",
      "Epoch 234/250\n",
      "12096/12096 [==============================] - 1s 60us/sample - loss: 0.2919 - acc: 0.8838 - val_loss: 0.4615 - val_acc: 0.8280\n",
      "Epoch 235/250\n",
      "12096/12096 [==============================] - 1s 61us/sample - loss: 0.2919 - acc: 0.8843 - val_loss: 0.4543 - val_acc: 0.8360\n",
      "Epoch 236/250\n",
      "12096/12096 [==============================] - 1s 61us/sample - loss: 0.2935 - acc: 0.8800 - val_loss: 0.4622 - val_acc: 0.8264\n",
      "Epoch 237/250\n",
      "12096/12096 [==============================] - 1s 59us/sample - loss: 0.2939 - acc: 0.8824 - val_loss: 0.4670 - val_acc: 0.8287\n",
      "Epoch 238/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.2872 - acc: 0.8838 - val_loss: 0.4691 - val_acc: 0.8330\n",
      "Epoch 239/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.2921 - acc: 0.8854 - val_loss: 0.4552 - val_acc: 0.8337\n",
      "Epoch 240/250\n",
      "12096/12096 [==============================] - 1s 58us/sample - loss: 0.2930 - acc: 0.8825 - val_loss: 0.4680 - val_acc: 0.8350\n",
      "Epoch 241/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.2904 - acc: 0.8839 - val_loss: 0.4585 - val_acc: 0.8347\n",
      "Epoch 242/250\n",
      "12096/12096 [==============================] - 1s 58us/sample - loss: 0.2872 - acc: 0.8852 - val_loss: 0.4710 - val_acc: 0.8280\n",
      "Epoch 243/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.2883 - acc: 0.8858 - val_loss: 0.4538 - val_acc: 0.8393\n",
      "Epoch 244/250\n",
      "12096/12096 [==============================] - 1s 56us/sample - loss: 0.2871 - acc: 0.8826 - val_loss: 0.4736 - val_acc: 0.8307\n",
      "Epoch 245/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.2891 - acc: 0.8847 - val_loss: 0.4712 - val_acc: 0.8244\n",
      "Epoch 246/250\n",
      "12096/12096 [==============================] - 1s 56us/sample - loss: 0.2913 - acc: 0.8839 - val_loss: 0.4704 - val_acc: 0.8267\n",
      "Epoch 247/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.2843 - acc: 0.8867 - val_loss: 0.4710 - val_acc: 0.8290\n",
      "Epoch 248/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.2851 - acc: 0.8857 - val_loss: 0.4562 - val_acc: 0.8323\n",
      "Epoch 249/250\n",
      "12096/12096 [==============================] - 1s 57us/sample - loss: 0.2866 - acc: 0.8846 - val_loss: 0.4764 - val_acc: 0.8304\n",
      "Epoch 250/250\n",
      "12096/12096 [==============================] - 1s 56us/sample - loss: 0.2856 - acc: 0.8828 - val_loss: 0.4735 - val_acc: 0.8353\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f90b7b61470>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the model\n",
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict!!\n",
    "y_predict = model.predict(x_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.8794880e-02 9.0312362e-01 1.4086723e-12 1.6156637e-16 4.3548578e-03\n",
      " 3.7266195e-03 5.8637487e-24] 2\n",
      "[5.5046115e-02 6.3986635e-01 7.6340850e-10 3.9300442e-13 3.0329975e-01\n",
      " 1.7877951e-03 3.1392076e-21] 2\n",
      "[5.1251240e-02 8.9108670e-01 3.0888173e-10 1.3277933e-12 5.6322265e-02\n",
      " 1.3398563e-03 1.8855041e-21] 2\n",
      "[3.6933254e-02 9.4412106e-01 1.1578282e-10 6.5304381e-12 1.6752902e-02\n",
      " 2.1927692e-03 1.0996842e-21] 2\n",
      "[2.6851648e-02 9.6310312e-01 6.6268248e-11 4.5178784e-11 6.0077095e-03\n",
      " 4.0375651e-03 3.6524639e-22] 2\n",
      "[3.58752310e-02 9.45886731e-01 1.11850154e-10 2.73890871e-12\n",
      " 1.42911077e-02 3.94684961e-03 1.71135649e-22] 2\n",
      "[4.7139239e-02 9.2674136e-01 1.3099853e-10 8.3363633e-13 2.2467950e-02\n",
      " 3.6514436e-03 5.3641249e-22] 2\n",
      "[4.5815326e-02 8.9776725e-01 2.3710850e-10 5.4704033e-13 5.3527337e-02\n",
      " 2.8900309e-03 5.3785152e-22] 2\n",
      "[8.9630134e-02 7.7242947e-01 1.1855985e-09 2.2447266e-13 1.3503878e-01\n",
      " 2.9016202e-03 1.0445658e-21] 2\n",
      "[6.6966169e-02 8.5741240e-01 3.7254697e-10 4.4693378e-13 7.1911111e-02\n",
      " 3.7103761e-03 1.0168681e-21] 2\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "\tprint(y_predict[i], np.argmax(y_predict[i])+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions to a file for submission\n",
    "#argmax give us the highest probable label\n",
    "# we add one to the predictions to scale from 0..6 to 1..7\n",
    "output = pd.DataFrame({'Id': Ids,\n",
    "                       'Cover_Type': y_predict.argmax(axis=1)+1})\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='submission.csv' target='_blank'>submission.csv</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/submission.csv"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a link to download the file    \n",
    "from IPython.display import FileLink\n",
    "FileLink(r'submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
