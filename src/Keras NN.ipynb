{"cells":[{"metadata":{},"cell_type":"markdown","source":"This is my first experiment in this competition. Whereas XGBoost is highly recommended I rather tried to see how far I can go with an NN (using Keras).\n\nThis is the basic model and with 250 epochs has an accuracy of 80% (really poor).\n\nI'll continue for a few days researching how much I can optimize this model."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nprint(os.listdir(\"../input/\"))\nprint(os.listdir(\"../working/\"))\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#load data, I had an issue with the data and hacked the data into the kernel\n#dftrain=pd.read_csv('/kaggle/input/train.csv')\n#dftest=pd.read_csv('/kaggle/input/test.csv')\ndftrain=pd.read_csv('/kaggle/input/learn-together/train.csv')\ndftest=pd.read_csv('/kaggle/input/learn-together/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#file shape\nprint(dftrain.head())\nprint(dftrain.shape[0])\nprint(dftest.head())\nprint(dftest.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#features types\nprint(dftrain.dtypes)\nprint(dftest.dtypes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#validate files - nans per feature\nprint(dftrain.isnull().sum(axis = 0))\nprint(dftest.isnull().sum(axis = 0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#validate files - no rows with all zeros\nprint(dftrain[dftrain.drop(['Id','Cover_Type'], axis=1).eq(0).all(1)].empty)\nprint(dftest[dftest.drop('Id', axis=1).eq(0).all(1)].empty)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#split train data in features and labels\ny = dftrain.Cover_Type\nx = dftrain.drop(['Id','Cover_Type'], axis=1)\n\n# split test data in features and Ids\nIds = dftest.Id\nx_predict = dftest.drop('Id', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#force all types to float\nx = x.astype(float)\nx_predict = x_predict.astype(float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#normalize features\n#in the future it can be done more elegantly, for now just using the max min values of the data that we know\n#x['Elevation']=(x['Elevation']-x['Elevation'].min())/(x['Elevation'].max()-x['Elevation'].min())                             \nx['Elevation']=(x['Elevation']-1859)/(3858-1859)                             \nx['Aspect']=x['Aspect']/360                      \nx['Slope']=x['Slope']/66                      \nx['Horizontal_Distance_To_Hydrology']=x['Horizontal_Distance_To_Hydrology']/1397                      \nx['Vertical_Distance_To_Hydrology']=(x['Vertical_Distance_To_Hydrology']+173)/(601+173)                             \nx['Horizontal_Distance_To_Roadways']=x['Horizontal_Distance_To_Roadways']/7117                      \nx['Hillshade_9am']=x['Hillshade_9am']/254                      \nx['Hillshade_Noon']=x['Hillshade_Noon']/254                      \nx['Hillshade_3pm']=x['Hillshade_3pm']/254                      \nx['Horizontal_Distance_To_Fire_Points']=x['Horizontal_Distance_To_Fire_Points']/67173                      \n                                \nx_predict['Elevation']=(x_predict['Elevation']-1859)/(3858-1859)                             \nx_predict['Aspect']=x_predict['Aspect']/360                      \nx_predict['Slope']=x_predict['Slope']/66                      \nx_predict['Horizontal_Distance_To_Hydrology']=x_predict['Horizontal_Distance_To_Hydrology']/1397                      \nx_predict['Vertical_Distance_To_Hydrology']=(x_predict['Vertical_Distance_To_Hydrology']+173)/(601+173)                             \nx_predict['Horizontal_Distance_To_Roadways']=x_predict['Horizontal_Distance_To_Roadways']/7117                      \nx_predict['Hillshade_9am']=x_predict['Hillshade_9am']/254                      \nx_predict['Hillshade_Noon']=x_predict['Hillshade_Noon']/254                      \nx_predict['Hillshade_3pm']=x_predict['Hillshade_3pm']/254                      \nx_predict['Horizontal_Distance_To_Fire_Points']=x_predict['Horizontal_Distance_To_Fire_Points']/67173                      ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#validate data - no rows with all zeros\n#x.index[x.eq(0).all(1)]\nprint(x[x.eq(0).all(1)].empty)\nprint(x_predict[x_predict.eq(0).all(1)].empty)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert the label to One Hot Encoding\n#to_categorical requires 0..6 instead of 1..7\ny -=1\ny = y.to_numpy()\n\nnum_classes = 7\n\nfrom tensorflow.keras.utils import to_categorical\ny = to_categorical(y, num_classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#convert the features dataframes to numpy arrays\nx = x.to_numpy()\nx_predict = x_predict.to_numpy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#split in train (80%) and test (20%) sets \nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y,test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#here is the NN model\nimport keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Dropout\n\nnum_features = 54\n\nmodel = Sequential()\nmodel.add(Dense(units=num_features*2, activation='relu', kernel_initializer='normal', input_dim=num_features)\nmodel.add(Dropout(0.2))\nmodel.add(Dense(units=num_features*2, activation='relu', kernel_initializer='normal'))\nmodel.add(Dense(num_classes, activation='softmax'))\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer='Adam',\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train the model\nmodel.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=250)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predict!!\ny_predict = model.predict(x_predict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(10):\n\tprint(y_predict[i], np.argmax(y_predict[i])+1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save predictions to a file for submission\n#argmax give us the highest probable label\n# we add one to the predictions to scale from 0..6 to 1..7\noutput = pd.DataFrame({'Id': Ids,\n                       'Cover_Type': y_predict.argmax(axis=1)+1})\noutput.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#create a link to download the file    \nfrom IPython.display import FileLink\nFileLink(r'submission.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}