{"cells":[{"metadata":{},"cell_type":"markdown","source":"I started this competition investigating neural networks with this kernel https://www.kaggle.com/mulargui/keras-nn\nNow switching to using ensembles in this new kernel. As of today V6 is the most performant version.\nYou can find all my notes and versions at https://github.com/mulargui/kaggle-Classify-forest-types"},{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n#load data\ndftrain=pd.read_csv('/kaggle/input/learn-together/train.csv')\ndftest=pd.read_csv('/kaggle/input/learn-together/test.csv')\n\n####### DATA PREPARATION #####\n#split train data in features and labels\ny = dftrain.Cover_Type\nx = dftrain.drop(['Id','Cover_Type'], axis=1)\n\n# split test data in features and Ids\nIds = dftest.Id\nx_predict = dftest.drop('Id', axis=1)\n\n# one data set with all features\nX = pd.concat([x,x_predict],keys=[0,1])","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"###### FEATURE ENGINEERING #####\n#https://www.kaggle.com/evimarp/top-6-roosevelt-national-forest-competition\nfrom itertools import combinations\nfrom bisect import bisect\nX['Euclidean_distance_to_hydro'] = (X.Vertical_Distance_To_Hydrology**2 \n                                         + X.Horizontal_Distance_To_Hydrology**2)**.5\n\ncols = [\n        'Horizontal_Distance_To_Roadways',\n        'Horizontal_Distance_To_Fire_Points',\n        'Horizontal_Distance_To_Hydrology',\n]\nX['distance_mean'] = X[cols].mean(axis=1)\nX['distance_sum'] = X[cols].sum(axis=1)\nX['distance_road_fire'] = X[cols[:2]].mean(axis=1)\nX['distance_hydro_fire'] = X[cols[1:]].mean(axis=1)\nX['distance_road_hydro'] = X[[cols[0], cols[2]]].mean(axis=1)\n    \nX['distance_sum_road_fire'] = X[cols[:2]].sum(axis=1)\nX['distance_sum_hydro_fire'] = X[cols[1:]].sum(axis=1)\nX['distance_sum_road_hydro'] = X[[cols[0], cols[2]]].sum(axis=1)\n    \nX['distance_dif_road_fire'] = X[cols[0]] - X[cols[1]]\nX['distance_dif_hydro_road'] = X[cols[2]] - X[cols[0]]\nX['distance_dif_hydro_fire'] = X[cols[2]] - X[cols[1]]\n    \n# Vertical distances measures\ncolv = ['Elevation', 'Vertical_Distance_To_Hydrology']\nX['Vertical_dif'] = X[colv[0]] - X[colv[1]]\nX['Vertical_sum'] = X[colv].sum(axis=1)\n    \nSHADES = ['Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm']\n    \nX['shade_noon_diff'] = X['Hillshade_9am'] - X['Hillshade_Noon']\nX['shade_3pm_diff'] = X['Hillshade_Noon'] - X['Hillshade_3pm']\nX['shade_all_diff'] = X['Hillshade_9am'] - X['Hillshade_3pm']\nX['shade_sum'] = X[SHADES].sum(axis=1)\nX['shade_mean'] = X[SHADES].mean(axis=1)\n  \nX['ElevationHydro'] = X['Elevation'] - 0.25 * X['Euclidean_distance_to_hydro']\nX['ElevationV'] = X['Elevation'] - X['Vertical_Distance_To_Hydrology']\nX['ElevationH'] = X['Elevation'] - 0.19 * X['Horizontal_Distance_To_Hydrology']\n\nX['Elevation2'] = X['Elevation']**2\nX['ElevationLog'] = np.log1p(X['Elevation'])\n\nX['Aspect_cos'] = np.cos(np.radians(X.Aspect))\nX['Aspect_sin'] = np.sin(np.radians(X.Aspect))\n#df['Slope_sin'] = np.sin(np.radians(df.Slope))\nX['Aspectcos_Slope'] = X.Slope * X.Aspect_cos\n#df['Aspectsin_Slope'] = df.Slope * df.Aspect_sin\n    \ncardinals = [i for i in range(45, 361, 90)]\npoints = ['N', 'E', 'S', 'W']\nX['Cardinal'] = X.Aspect.apply(lambda x: points[bisect(cardinals, x) % 4])\nd = {'N': 0, 'E': 1, 'S': 0, 'W':-1}\nX['Cardinal'] = X.Cardinal.apply(lambda x: d[x])\n\n#adding features based on https://douglas-fraser.com/forest_cover_management.pdf pages 21,22\n#note: not all climatic and geologic codes have a soil type\ncolumns=['Soil_Type1', 'Soil_Type2', 'Soil_Type3', 'Soil_Type4', 'Soil_Type5', 'Soil_Type6']\nX['Climatic2'] = np.select([X[columns].sum(1).gt(0)], [1])\ncolumns=['Soil_Type7', 'Soil_Type8']\nX['Climatic3'] = np.select([X[columns].sum(1).gt(0)], [1])\ncolumns=['Soil_Type9', 'Soil_Type10', 'Soil_Type11', 'Soil_Type12', 'Soil_Type13']\nX['Climatic4'] = np.select([X[columns].sum(1).gt(0)], [1])\ncolumns=['Soil_Type14', 'Soil_Type15']\nX['Climatic5'] = np.select([X[columns].sum(1).gt(0)], [1])\ncolumns=['Soil_Type16', 'Soil_Type17', 'Soil_Type18']\nX['Climatic6'] = np.select([X[columns].sum(1).gt(0)], [1])\ncolumns=['Soil_Type19', 'Soil_Type20', 'Soil_Type21', 'Soil_Type22', 'Soil_Type23', 'Soil_Type24',\n    'Soil_Type25', 'Soil_Type26', 'Soil_Type27', 'Soil_Type28', 'Soil_Type29', 'Soil_Type30',\n    'Soil_Type31', 'Soil_Type32', 'Soil_Type33', 'Soil_Type34']\nX['Climatic7'] = np.select([X[columns].sum(1).gt(0)], [1])\ncolumns=['Soil_Type35', 'Soil_Type36', 'Soil_Type37', 'Soil_Type38', 'Soil_Type39', 'Soil_Type40']\nX['Climatic8'] = np.select([X[columns].sum(1).gt(0)], [1])\n\ncolumns=['Soil_Type14', 'Soil_Type15', 'Soil_Type16', 'Soil_Type17', 'Soil_Type19', 'Soil_Type20',\n    'Soil_Type21']\nX['Geologic1'] = np.select([X[columns].sum(1).gt(0)], [1])\ncolumns=['Soil_Type9', 'Soil_Type22', 'Soil_Type23']\nX['Geologic2'] = np.select([X[columns].sum(1).gt(0)], [1])\ncolumns=['Soil_Type7', 'Soil_Type8']\nX['Geologic5'] = np.select([X[columns].sum(1).gt(0)], [1])\ncolumns=['Soil_Type1', 'Soil_Type2', 'Soil_Type3', 'Soil_Type4', 'Soil_Type5', 'Soil_Type6',\n    'Soil_Type10', 'Soil_Type11', 'Soil_Type12', 'Soil_Type13', 'Soil_Type18', 'Soil_Type24',\n    'Soil_Type25', 'Soil_Type26', 'Soil_Type27', 'Soil_Type28', 'Soil_Type29', 'Soil_Type30',\n    'Soil_Type31', 'Soil_Type32', 'Soil_Type33', 'Soil_Type34', 'Soil_Type35', 'Soil_Type36', \n    'Soil_Type37', 'Soil_Type38', 'Soil_Type39', 'Soil_Type40']\nX['Geologic7'] = np.select([X[columns].sum(1).gt(0)], [1])\n\n#Reversing One-Hot-Encoding to Categorical attributes, several articles recommend it for decision tree algorithms\n#Doing it for Soil_Type, Wilderness_Area, Geologic and Climatic\nX['Soil_Type']=np.where(X.loc[:, 'Soil_Type1':'Soil_Type40'])[1] +1\nX.drop(X.loc[:,'Soil_Type1':'Soil_Type40'].columns, axis=1, inplace=True)\n\nX['Wilderness_Area']=np.where(X.loc[:, 'Wilderness_Area1':'Wilderness_Area4'])[1] +1\nX.drop(X.loc[:,'Wilderness_Area1':'Wilderness_Area4'].columns, axis=1, inplace=True)\n\nX['Climatic']=np.where(X.loc[:, 'Climatic2':'Climatic8'])[1] +1\nX.drop(X.loc[:,'Climatic2':'Climatic8'].columns, axis=1, inplace=True)\n\nX['Geologic']=np.where(X.loc[:, 'Geologic1':'Geologic7'])[1] +1\nX.drop(X.loc[:,'Geologic1':'Geologic7'].columns, axis=1, inplace=True)\n\nfrom sklearn.preprocessing import StandardScaler\nStandardScaler(copy=False).fit_transform(X)\n\n# Adding Gaussian Mixture features to perform some unsupervised learning hints from the full data\n#https://www.kaggle.com/arateris/2-layer-k-fold-learning-forest-cover \n#https://www.kaggle.com/stevegreenau/stacking-multiple-classifiers-clustering\nfrom sklearn.mixture import GaussianMixture\nX['GM'] = GaussianMixture(n_components=y.nunique()).fit_predict(X)\n\n#https://www.kaggle.com/arateris/2-layer-k-fold-learning-forest-cover \n# Add PCA features\nfrom sklearn.decomposition import PCA\npca = PCA(n_components=0.99).fit(X)\ntrans = pca.transform(X)\n\nfor i in range(trans.shape[1]):\n    col_name= 'pca'+str(i+1)\n    X[col_name] = trans[:,i]\n\n#https://www.kaggle.com/arateris/2-layer-k-fold-learning-forest-cover \n# Scale and bin features\nfrom sklearn.preprocessing import MinMaxScaler\nMinMaxScaler((0, 100),copy=False).fit_transform(X)\n#X = np.floor(X).astype('int8')","execution_count":10,"outputs":[{"output_type":"stream","text":"1\n2\n3\n4\n5\n6\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#break it down again in train and test\nx,x_predict = X.xs(0),X.xs(1)","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"###### THIS IS THE ENSEMBLE SECTION ######\n#https://www.kaggle.com/kwabenantim/forest-cover-stacking-multiple-classifiers\nimport random\nrandomstate = 1\nrandom.seed(randomstate)\nnp.random.seed(randomstate)\n\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nab_clf = AdaBoostClassifier(n_estimators=200,\n                            base_estimator=DecisionTreeClassifier(\n                                min_samples_leaf=2,\n                                random_state=randomstate),\n                            random_state=randomstate)\n\n#max_features = min(30, x.columns.size)\nmax_features = 30\nfrom sklearn.ensemble import ExtraTreesClassifier\net_clf = ExtraTreesClassifier(n_estimators=300,\n                              min_samples_leaf=2,\n                              min_samples_split=2,\n                              max_depth=50,\n                              max_features=max_features,\n                              random_state=randomstate,\n                              n_jobs=1)\n\nfrom lightgbm import LGBMClassifier\nlg_clf = LGBMClassifier(n_estimators=300,\n                        num_leaves=128,\n                        verbose=-1,\n                        random_state=randomstate,\n                        n_jobs=1)\n\nfrom sklearn.ensemble import RandomForestClassifier\nrf_clf = RandomForestClassifier(n_estimators=300,\n                                random_state=randomstate,\n                                n_jobs=1)\n\n#Added a KNN classifier to the ensemble\n#https://www.kaggle.com/edumunozsala/feature-eng-and-a-simple-stacked-model\nfrom sklearn.neighbors import KNeighborsClassifier\nknn_clf = KNeighborsClassifier(n_neighbors=y.nunique(), n_jobs=1)\n\n#added several more classifiers at once\n#https://www.kaggle.com/edumunozsala/feature-eng-and-a-simple-stacked-model\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nbag_clf = BaggingClassifier(base_estimator=DecisionTreeClassifier(criterion = 'entropy', max_depth=None, \n                                                    min_samples_split=2, min_samples_leaf=1,max_leaf_nodes=None,\n                                                    max_features='auto',\n                                                    random_state = randomstate),\n                    n_estimators=500,max_features=0.75, max_samples=1.0, random_state=randomstate,n_jobs=1,verbose=0)\n\nfrom sklearn.linear_model import LogisticRegression\nlr_clf = LogisticRegression(max_iter=1000,\n                       n_jobs=1,\n                       solver= 'lbfgs',\n                       multi_class = 'multinomial',\n                       random_state=randomstate,\n                       verbose=0)\n\n#https://www.kaggle.com/bustam/6-models-for-forest-classification\nfrom catboost import CatBoostClassifier\ncat_clf = CatBoostClassifier(n_estimators =300, \n                        eval_metric='Accuracy',\n                        metric_period=200,\n                        max_depth = None, \n                        random_state=randomstate,\n                        verbose=0)\n\n#https://www.kaggle.com/jakelj/basic-ensemble-model\nfrom sklearn.experimental import enable_hist_gradient_boosting\nfrom sklearn.ensemble import HistGradientBoostingClassifier\nhbc_clf = HistGradientBoostingClassifier(max_iter = 500, max_depth =25, random_state = randomstate)\n\nensemble = [('AdaBoostClassifier', ab_clf),\n            ('ExtraTreesClassifier', et_clf),\n            ('LGBMClassifier', lg_clf),\n            ('KNNClassifier', knn_clf),\n            ('BaggingClassifier', bag_clf),\n            ('LogRegressionClassifier', lr_clf),\n            ('CatBoostClassifier', cat_clf),\n            #('HBCClassifier', hbc_clf),\n            ('RandomForestClassifier', rf_clf)\n]\n\n#Cross-validating classifiers\nfrom sklearn.model_selection import cross_val_score\nfor label, clf in ensemble:\n    score = cross_val_score(clf, x, y,\n                            cv=5,\n                            scoring='accuracy',\n                            verbose=0,\n                            n_jobs=-1)\n    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" \n        % (score.mean(), score.std(), label))\n\n# Fitting stack\nfrom mlxtend.classifier import StackingCVClassifier\nstack = StackingCVClassifier(classifiers=[ab_clf, et_clf, lg_clf, knn_clf, \n                                          bag_clf, lr_clf, cat_clf,\n                                          rf_clf],\n                             meta_classifier=rf_clf,\n                             cv=5,\n                             stratify=True,\n                             shuffle=True,\n                             use_probas=True,\n                             use_features_in_secondary=True,\n                             verbose=0,\n                             random_state=randomstate)\nstack = stack.fit(x, y)\n\ny_predict = stack.predict(x_predict)\ny_predict = pd.Series(y_predict, index=x_predict.index, dtype=y.dtype)","execution_count":14,"outputs":[{"output_type":"stream","text":"Accuracy: 0.80 (+/- 0.04) [AdaBoostClassifier]\nAccuracy: 0.81 (+/- 0.04) [ExtraTreesClassifier]\nAccuracy: 0.82 (+/- 0.03) [LGBMClassifier]\nAccuracy: 0.53 (+/- 0.03) [KNNClassifier]\nAccuracy: 0.80 (+/- 0.03) [BaggingClassifier]\nAccuracy: 0.56 (+/- 0.05) [LogRegressionClassifier]\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n","name":"stderr"},{"output_type":"stream","text":"Accuracy: 0.73 (+/- 0.03) [CatBoostClassifier]\n","name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-ef9a7d4eee17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     92\u001b[0m                             \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                             n_jobs=-1)\n\u001b[0m\u001b[1;32m     95\u001b[0m     print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" \n\u001b[1;32m     96\u001b[0m         % (score.mean(), score.std(), label))\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    389\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m                                 error_score=error_score)\n\u001b[0m\u001b[1;32m    392\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 232\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save predictions to a file for submission\noutput = pd.DataFrame({'Id': Ids,\n                       'Cover_Type': y_predict})\noutput.to_csv('submission.csv', index=False)\n\n#create a link to download the file    \nfrom IPython.display import FileLink\nFileLink(r'submission.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}