{"cells":[{"metadata":{},"cell_type":"markdown","source":"I started this competition investigating neural networks with this kernel https://www.kaggle.com/mulargui/keras-nn\nNow switching to using ensembles in this new kernel.\nYou can find all my notes and versions at https://github.com/mulargui/kaggle-Classify-forest-types"},{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n#load data\ndftrain=pd.read_csv('/kaggle/input/learn-together/train.csv')\ndftest=pd.read_csv('/kaggle/input/learn-together/test.csv')\n\n####### DATA PREPARATION #####\n#split train data in features and labels\ny = dftrain.Cover_Type\nx = dftrain.drop(['Id','Cover_Type'], axis=1)\n\n# split test data in features and Ids\nIds = dftest.Id\nx_predict = dftest.drop('Id', axis=1)\n\n# one data set with all features\nX = pd.concat([x,x_predict],keys=[0,1])","execution_count":57,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"###### FEATURE ENGINEERING #####\n#https://www.kaggle.com/arateris/2-layer-k-fold-learning-forest-cover \n#Fixing Hillshade_3pm\n#replacing the zeros for better guess, mainly to avoid zeros in the feature engineering and fake outliers. \ncols_for_HS = ['Aspect','Slope', 'Hillshade_9am','Hillshade_Noon']\nHS_zero = X[X.Hillshade_3pm==0]\nHS_train = X[X.Hillshade_3pm!=0]\n\nfrom sklearn.ensemble import RandomForestRegressor\nrf_hs = RandomForestRegressor(n_estimators=100).fit(HS_train[cols_for_HS], HS_train.Hillshade_3pm)\nout = rf_hs.predict(HS_zero[cols_for_HS]).astype(int)\n#X.loc[HS_zero.index,'Hillshade_3pm'] = out\n\n# Adding Gaussian Mixture features to perform some unsupervised learning hints from the full data\n#https://www.kaggle.com/arateris/2-layer-k-fold-learning-forest-cover \n#https://www.kaggle.com/stevegreenau/stacking-multiple-classifiers-clustering\nfrom sklearn.mixture import GaussianMixture\nfrom sklearn.preprocessing import StandardScaler\ngmix = GaussianMixture(n_components=10) \ngaussian = gmix.fit_predict(StandardScaler().fit_transform(X))\nX['GM'] = gaussian\n\n#https://www.kaggle.com/evimarp/top-6-roosevelt-national-forest-competition\nfrom itertools import combinations\nfrom bisect import bisect\ndef features(df):\n    df['Euclidean_distance_to_hydro'] = (df.Vertical_Distance_To_Hydrology**2 \n                                         + df.Horizontal_Distance_To_Hydrology**2)**.5\n\n    cols = [\n        'Horizontal_Distance_To_Roadways',\n        'Horizontal_Distance_To_Fire_Points',\n        'Horizontal_Distance_To_Hydrology',\n    ]\n    df['distance_mean'] = df[cols].mean(axis=1)\n    df['distance_sum'] = df[cols].sum(axis=1)\n    df['distance_road_fire'] = df[cols[:2]].mean(axis=1)\n    df['distance_hydro_fire'] = df[cols[1:]].mean(axis=1)\n    df['distance_road_hydro'] = df[[cols[0], cols[2]]].mean(axis=1)\n    \n    df['distance_sum_road_fire'] = df[cols[:2]].sum(axis=1)\n    df['distance_sum_hydro_fire'] = df[cols[1:]].sum(axis=1)\n    df['distance_sum_road_hydro'] = df[[cols[0], cols[2]]].sum(axis=1)\n    \n    df['distance_dif_road_fire'] = df[cols[0]] - df[cols[1]]\n    df['distance_dif_hydro_road'] = df[cols[2]] - df[cols[0]]\n    df['distance_dif_hydro_fire'] = df[cols[2]] - df[cols[1]]\n    \n    # Vertical distances measures\n    colv = ['Elevation', 'Vertical_Distance_To_Hydrology']\n    df['Vertical_dif'] = df[colv[0]] - df[colv[1]]\n    df['Vertical_sum'] = df[colv].sum(axis=1)\n    \n    SHADES = ['Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm']\n    \n    df['shade_noon_diff'] = df['Hillshade_9am'] - df['Hillshade_Noon']\n    df['shade_3pm_diff'] = df['Hillshade_Noon'] - df['Hillshade_3pm']\n    df['shade_all_diff'] = df['Hillshade_9am'] - df['Hillshade_3pm']\n    df['shade_sum'] = df[SHADES].sum(axis=1)\n    df['shade_mean'] = df[SHADES].mean(axis=1)\n    \n    df['ElevationHydro'] = df['Elevation'] - 0.25 * df['Euclidean_distance_to_hydro']\n    df['ElevationV'] = df['Elevation'] - df['Vertical_Distance_To_Hydrology']\n    df['ElevationH'] = df['Elevation'] - 0.19 * df['Horizontal_Distance_To_Hydrology']\n\n    df['Elevation2'] = df['Elevation']**2\n    df['ElevationLog'] = np.log1p(df['Elevation'])\n\n    df['Aspect_cos'] = np.cos(np.radians(df.Aspect))\n    df['Aspect_sin'] = np.sin(np.radians(df.Aspect))\n    #df['Slope_sin'] = np.sin(np.radians(df.Slope))\n    df['Aspectcos_Slope'] = df.Slope * df.Aspect_cos\n    #df['Aspectsin_Slope'] = df.Slope * df.Aspect_sin\n    \n    cardinals = [i for i in range(45, 361, 90)]\n    points = ['N', 'E', 'S', 'W']\n    df['Cardinal'] = df.Aspect.apply(lambda x: points[bisect(cardinals, x) % 4])\n\n    d = {'N': 0, 'E': 1, 'S': 0, 'W':-1}\n    df['Cardinal'] = df.Cardinal.apply(lambda x: d[x])\n    return df\n\nX = features(X)\n\n#adding features based on https://douglas-fraser.com/forest_cover_management.pdf pages 21,22\n#note: not all climatic and geologic codes have a soil type\n\ndef Climatic2(row): \n    if (row['Soil_Type1'] == 1) or (row['Soil_Type2'] == 1) or (row['Soil_Type3'] == 1) or (row['Soil_Type4'] == 1) \\\n        or (row['Soil_Type5'] == 1) or (row['Soil_Type6'] == 1) :\n        return 1 \n    return 0\n\nX['Climatic2'] = X.apply (lambda row: Climatic2(row), axis=1)\n\ndef Climatic3(row): \n    if (row['Soil_Type7'] == 1) or (row['Soil_Type8'] == 1) :\n        return 1 \n    return 0\n\nX['Climatic3'] = X.apply (lambda row: Climatic3(row), axis=1)\n\ndef Climatic4(row): \n    if (row['Soil_Type9'] == 1) or (row['Soil_Type10'] == 1) or (row['Soil_Type11'] == 1) or (row['Soil_Type12'] == 1) \\\n        or (row['Soil_Type13'] == 1) :\n        return 1 \n    return 0\n\nX['Climatic4'] = X.apply (lambda row: Climatic4(row), axis=1)\n\ndef Climatic5(row): \n    if (row['Soil_Type14'] == 1) or (row['Soil_Type15'] == 1) :\n        return 1 \n    return 0\n\nX['Climatic5'] = X.apply (lambda row: Climatic5(row), axis=1)\n\ndef Climatic6(row): \n    if (row['Soil_Type16'] == 1) or (row['Soil_Type17'] == 1) or (row['Soil_Type18'] == 1) :\n        return 1 \n    return 0\n\nX['Climatic6'] = X.apply (lambda row: Climatic6(row), axis=1)\n\ndef Climatic7(row): \n    if (row['Soil_Type19'] == 1) or (row['Soil_Type20'] == 1) or (row['Soil_Type21'] == 1) or (row['Soil_Type22'] == 1) \\\n        or (row['Soil_Type23'] == 1) or (row['Soil_Type24'] == 1) or (row['Soil_Type25'] == 1) or (row['Soil_Type26'] == 1) \\\n        or (row['Soil_Type27'] == 1) or (row['Soil_Type28'] == 1) or (row['Soil_Type29'] == 1) or (row['Soil_Type30'] == 1) \\\n        or (row['Soil_Type31'] == 1) or (row['Soil_Type32'] == 1) or (row['Soil_Type33'] == 1) or (row['Soil_Type34'] == 1) :\n        return 1 \n    return 0\n\nX['Climatic7'] = X.apply (lambda row: Climatic7(row), axis=1)\n\ndef Climatic8(row): \n    if (row['Soil_Type35'] == 1) or (row['Soil_Type36'] == 1) or (row['Soil_Type37'] == 1) or (row['Soil_Type38'] == 1) \\\n        or (row['Soil_Type39'] == 1) or (row['Soil_Type40'] == 1) :\n        return 1 \n    return 0\n\nX['Climatic8'] = X.apply (lambda row: Climatic8(row), axis=1)\n\ndef Geologic1(row): \n    if (row['Soil_Type14'] == 1) or (row['Soil_Type15'] == 1) or (row['Soil_Type16'] == 1) or (row['Soil_Type17'] == 1) \\\n        or (row['Soil_Type19'] == 1) or (row['Soil_Type20'] == 1) or (row['Soil_Type21'] == 1) :\n        return 1 \n    return 0\n\nX['Geologic1'] = X.apply (lambda row: Geologic1(row), axis=1)\n\ndef Geologic2(row): \n    if (row['Soil_Type9'] == 1) or (row['Soil_Type22'] == 1) or (row['Soil_Type23'] == 1) :\n        return 1 \n    return 0\n\nX['Geologic2'] = X.apply (lambda row: Geologic2(row), axis=1)\n\ndef Geologic5(row): \n    if (row['Soil_Type7'] == 1) or (row['Soil_Type8'] == 1) :\n        return 1 \n    return 0\n\nX['Geologic5'] = X.apply (lambda row: Geologic5(row), axis=1)\n\ndef Geologic7(row): \n    if (row['Soil_Type1'] == 1) or (row['Soil_Type2'] == 1) or (row['Soil_Type3'] == 1) or (row['Soil_Type4'] == 1) \\\n        or (row['Soil_Type5'] == 1) or (row['Soil_Type6'] == 1) or (row['Soil_Type10'] == 1) \\\n        or (row['Soil_Type11'] == 1) or (row['Soil_Type12'] == 1) or (row['Soil_Type13'] == 1) or (row['Soil_Type18'] == 1) \\\n        or (row['Soil_Type24'] == 1) or (row['Soil_Type25'] == 1) or (row['Soil_Type26'] == 1) or (row['Soil_Type27'] == 1) \\\n        or (row['Soil_Type28'] == 1) or (row['Soil_Type29'] == 1) or (row['Soil_Type30'] == 1) or (row['Soil_Type31'] == 1) \\\n        or (row['Soil_Type32'] == 1) or (row['Soil_Type33'] == 1) or (row['Soil_Type34'] == 1) or (row['Soil_Type35'] == 1) \\\n        or (row['Soil_Type36'] == 1) or (row['Soil_Type37'] == 1) or (row['Soil_Type38'] == 1) or (row['Soil_Type39'] == 1) \\\n        or (row['Soil_Type40'] == 1) :\n        return 1 \n    return 0\n\nX['Geologic7'] = X.apply (lambda row: Geologic7(row), axis=1)\n\n#Reversing One-Hot-Encoding to Categorical attributes, several articles recommend it for decision tree algorithms\n#Doing it for Soil_Type, Wilderness_Area, Geologic and Climatic\n#we are also replacing the categorical values by random numbers to difficult to the algorythm to find relationships between the values\nX['Tmp']=np.where(X.loc[:, 'Soil_Type1':'Soil_Type40'])[1] +1\ncols = [c for c in X.columns if c[:9] != 'Soil_Type']\nX=X[cols]\nX=X.rename(columns = {'Tmp':'Soil_Type'})\n\nmin=X['Soil_Type'].min()\nmax=X['Soil_Type'].max()\ns=np.random.randint(low=1, high=np.iinfo(np.int64).max, size=(max-min+1), dtype='int64')\nfor i in range (min,max+1):\n    X['Soil_Type'].replace(to_replace=i, value=s[i-min], inplace=True)\n\nX['Tmp']=np.where(X.loc[:, 'Wilderness_Area1':'Wilderness_Area4'])[1] +1\ncols = [c for c in X.columns if c[:15] != 'Wilderness_Area']\nX=X[cols]\nX=X.rename(columns = {'Tmp':'Wilderness_Area'})\n\nmin=X['Wilderness_Area'].min()\nmax=X['Wilderness_Area'].max()\ns=np.random.randint(low=1, high=np.iinfo(np.int64).max, size=(max-min+1), dtype='int64')\nfor i in range (min,max+1):\n    X['Wilderness_Area'].replace(to_replace=i, value=s[i-min], inplace=True)\n\nX['Tmp']=np.where(X.loc[:, 'Climatic2':'Climatic8'])[1] +1\ncols = [c for c in X.columns if c[:8] != 'Climatic']\nX=X[cols]\nX=X.rename(columns = {'Tmp':'Climatic'})\n\nmin=X['Climatic'].min()\nmax=X['Climatic'].max()\ns=np.random.randint(low=1, high=np.iinfo(np.int64).max, size=(max-min+1), dtype='int64')\nfor i in range (min,max+1):\n    X['Climatic'].replace(to_replace=i, value=s[i-min], inplace=True)\n\nX['Tmp']=np.where(X.loc[:, 'Geologic1':'Geologic7'])[1] +1\ncols = [c for c in X.columns if c[:8] != 'Geologic']\nX=X[cols]\nX=X.rename(columns = {'Tmp':'Geologic'})\n\nmin=X['Geologic'].min()\nmax=X['Geologic'].max()\ns=np.random.randint(low=1, high=np.iinfo(np.int64).max, size=(max-min+1), dtype='int64')\nfor i in range (min,max+1):\n    X['Geologic'].replace(to_replace=i, value=s[i-min], inplace=True)\n\n#https://www.kaggle.com/arateris/2-layer-k-fold-learning-forest-cover \n# Add PCA features\nfrom sklearn.decomposition import PCA\npca = PCA(n_components=0.99).fit(X)\ntrans = pca.transform(X)\n\nfor i in range(trans.shape[1]):\n    col_name= 'pca'+str(i+1)\n    X[col_name] = trans[:,i]\n\n# Scale and bin features\nfrom sklearn.preprocessing import MinMaxScaler\nX.loc[:, :] = np.floor(MinMaxScaler((0, 100)).fit_transform(X))\nX = X.astype('int8')","execution_count":58,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#break it down again in train and test\nx,x_predict = X.xs(0),X.xs(1)","execution_count":59,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"###### THIS IS THE ENSEMBLE SECTION ######\n#https://www.kaggle.com/kwabenantim/forest-cover-stacking-multiple-classifiers\nimport random\nfrom lightgbm import LGBMClassifier\nfrom mlxtend.classifier import StackingCVClassifier\nfrom sklearn.ensemble import AdaBoostClassifier, ExtraTreesClassifier, RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.tree import DecisionTreeClassifier\n\nrandomstate = 1\nrandom.seed(randomstate)\nnp.random.seed(randomstate)\n\n#max_features = min(30, x.columns.size)\nmax_features = 30\n\nab_clf = AdaBoostClassifier(n_estimators=200,\n                            base_estimator=DecisionTreeClassifier(\n                                min_samples_leaf=2,\n                                random_state=randomstate),\n                            random_state=randomstate)\n\net_clf = ExtraTreesClassifier(n_estimators=300,\n                              min_samples_leaf=2,\n                              min_samples_split=2,\n                              max_depth=50,\n                              max_features=max_features,\n                              random_state=randomstate,\n                              n_jobs=1)\n\nlg_clf = LGBMClassifier(n_estimators=300,\n                        num_leaves=128,\n                        verbose=-1,\n                        random_state=randomstate,\n                        n_jobs=1)\n\nrf_clf = RandomForestClassifier(n_estimators=300,\n                                random_state=randomstate,\n                                n_jobs=1)\n\nensemble = [('AdaBoostClassifier', ab_clf),\n            ('ExtraTreesClassifier', et_clf),\n            ('LGBMClassifier', lg_clf),\n            ('RandomForestClassifier', rf_clf)]\n\n#Cross-validating classifiers\nfor label, clf in ensemble:\n    score = cross_val_score(clf, x, y,\n                            cv=5,\n                            scoring='accuracy',\n                            verbose=0,\n                            n_jobs=-1)\n# Fitting stack\nstack = StackingCVClassifier(classifiers=[ab_clf, et_clf, lg_clf, rf_clf],\n                             meta_classifier=rf_clf,\n                             cv=5,\n                             stratify=True,\n                             shuffle=True,\n                             use_probas=True,\n                             use_features_in_secondary=True,\n                             verbose=1,\n                             random_state=randomstate)\n\nstack = stack.fit(x, y)\n\ny_predict = stack.predict(x_predict)\ny_predict = pd.Series(y_predict, index=x_predict.index, dtype=y.dtype)","execution_count":61,"outputs":[{"output_type":"stream","text":"Fitting 4 classifiers...\nFitting classifier1: adaboostclassifier (1/4)\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  5.6min finished\n[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","name":"stderr"},{"output_type":"stream","text":"Fitting classifier2: extratreesclassifier (2/4)\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  1.3min finished\n[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","name":"stderr"},{"output_type":"stream","text":"Fitting classifier3: lgbmclassifier (3/4)\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  2.8min finished\n[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","name":"stderr"},{"output_type":"stream","text":"Fitting classifier4: randomforestclassifier (4/4)\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   53.7s finished\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save predictions to a file for submission\noutput = pd.DataFrame({'Id': Ids,\n                       'Cover_Type': y_predict})\noutput.to_csv('submission.csv', index=False)\n\n#create a link to download the file    \nfrom IPython.display import FileLink\nFileLink(r'submission.csv')","execution_count":62,"outputs":[{"output_type":"execute_result","execution_count":62,"data":{"text/plain":"/kaggle/working/submission.csv","text/html":"<a href='submission.csv' target='_blank'>submission.csv</a><br>"},"metadata":{}}]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}