When I started planning for experiment 21 I discovered this dataset was used before at Kaggle in a competition and also there is literature available online. Adding this info at the top of the diary.
Some links in no special order

https://archive.ics.uci.edu/ml/datasets/Covertype
https://ieeexplore.ieee.org/document/7154873
https://www.kaggle.com/c/forest-cover-type-prediction

https://douglas-fraser.com/forest_cover_management.pdf
https://github.com/jaustinrdi/kaggle/blob/master/kaggle_forest/guschin_example.py#L64
https://www.kaggle.com/kwabenantim/forest-cover-feature-engineering
https://www.kaggle.com/jakelj/basic-ensemble-model
https://www.kaggle.com/arthurtok/introduction-to-ensembling-stacking-in-python
https://rstudio-pubs-static.s3.amazonaws.com/160297_f7bcb8d140b74bd19b758eb328344908.html

https://mlwave.com/kaggle-ensembling-guide/
https://www.kaggle.com/c/ieee-fraud-detection/discussion/108575
https://www.kaggle.com/serigne/stacked-regressions-top-4-on-leaderboard
https://www.kaggle.com/shahules/tackling-class-imbalance

==================================================================================

Here are notes of ideas explored during the project
1.Created the basic Keras NN model
	Accuracy in Keras 82%
	336 in the leaderboard (0.676 score)
2.Incremented training data (90%) vs validation (10%)
	x_train, x_test, y_train, y_test = train_test_split(x, y,test_size=0.1)
	Accuracy in Keras 82%
	no improvement - cancelled
3.Added a second layer to the NN of the same size the first level
	model.add(Dense(units=num_features, activation='relu', kernel_initializer='normal'))
	Accuracy in Keras 85%
4.Added a second layer to the NN of half the size the first level
	model.add(Dense(units=num_features/2, activation='relu', kernel_initializer='normal'))
	Accuracy in Keras 83%
5.Added a second layer to the NN of double the size the first level
	model.add(Dense(units=num_features*2, activation='relu', kernel_initializer='normal'))
	Accuracy in Keras sample - loss: 0.2847 - acc: 0.8867 - val_loss: 0.4952 - val_acc: 0.8287
	341 in the leaderboard (0.71187 score)
6.Added a 3 more layers to the NN of the same size the second level (exp. 5)
	Accuracy in Keras 97%
	464 in the leaderboard (0.70321 score) which is worst. Overfitting?
7.Added a 20% dropout between hidden layers
	Accuracy in Keras sample - loss: 0.4901 - acc: 0.8008 - val_loss: 0.4953 - val_acc: 0.7953
	464 in the leaderboard (0.67128 score) which is worst. Overfitting?
8.Made the hidden layers very wide: 10 times the number of features
	Accuracy in Keras sample - loss: 0.3853 - acc: 0.8448 - val_loss: 0.4861 - val_acc: 0.8185
	464 in the leaderboard (0.68662 score) which is worst. Overfitting?
9.Build a deep NN with 10 hidden layers (double the number of features, exp. 5) and 20% dropout between layers
	Accuracy in Keras sample - loss: 0.6217 - acc: 0.7475 - val_loss: 0.5988 - val_acc: 0.7735
	0.63091 score in the leaderboard, which is worst
10. Back to exp. 5, which has the best performance and added a 20% dropout between all layers
	Accuracy in Keras sample - loss: 0.4376 - acc: 0.8205 - val_loss: 0.4711 - val_acc: 0.8158
11. Like exp. 10, but only dropout before the output layer
	Accuracy in Keras sample - loss: 0.3358 - acc: 0.8657 - val_loss: 0.4851 - val_acc: 0.8224
12. Like exp. 10, but only dropout after the input layer
	Accuracy in Keras sample - loss: 0.4052 - acc: 0.8339 - val_loss: 0.4592 - val_acc: 0.8201
13. Like exp. 10, but added kernel_constraint
	model.add(Dense(units=num_features, activation='relu', kernel_initializer='normal', input_dim=num_features, kernel_constraint=MaxNorm(3)))
	Accuracy in Keras sample - loss: 0.4527 - acc: 0.8141 - val_loss: 0.4651 - val_acc: 0.8158
	no improvement vs 10
14. Exp. 5 (best performing) doubling the number of first layer units
	model.add(Dense(units=num_features*2, activation='relu', kernel_initializer='normal', input_dim=num_features))
	Accuracy in Keras sample - loss: 0.2235 - acc: 0.9136 - val_loss: 0.5131 - val_acc: 0.8390
	0.71393 in the leaderboard - better than exp. 5!
15. Added 20% dropout to exp. 14
	Accuracy in Keras sample - loss: 0.3079 - acc: 0.8738 - val_loss: 0.4411 - val_acc: 0.8433
	0.72000 in the leaderboard - better than exp. 14!
16. added kernel constraints following academic papers
	Accuracy in Keras sample - loss: 0.3235 - acc: 0.8708 - val_loss: 0.4293 - val_acc: 0.8479
	0.63 in the leaderboard - cancelled
17. Cleaned up and compacted code of 15. Created ExploreData separately.
	No new data.
======================================================================================
20. First attempt to use XGBoost. 
	Accuracy: 74.54%
	0.58569 in the leaderboard - poor!
21. Discovered more info about this dataset online
22. Based on https://douglas-fraser.com/forest_cover_management.pdf pages 21,22 I'm adding 2 cathegorical features embedded in soiltype ELUs first and second digit classification
	Accuracy: 76.46%
	0.59955  in the leaderboard - very little improvement
23. Based on several articles reversed OneHotEncoding in several features to categorical features
	Accuracy: 74.87%
	0.59721 in the leaderboard - no improvement
24. Added plenty of features inspired by other kernels.V10 in kaggle
	Accuracy:  79.83%
	0.58623 in the leaderboard - no improvement
======================================================================================
25. Added all the engineered features to the NN model. V14 in kaggle
	Accuracy in Keras sample - loss: 0.1600 - acc: 0.9382 - val_loss: 0.4902 - val_acc: 0.8657
	0.74767 in the leaderboard - 2 percent improvement
